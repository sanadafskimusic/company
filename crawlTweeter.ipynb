{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "toc5ZG9QNiKb",
        "outputId": "8ab3129d-50b7-48ab-dace-31e345baf97d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tweepy in /usr/local/lib/python3.10/dist-packages (4.14.0)\n",
            "Requirement already satisfied: oauthlib<4,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tweepy) (3.2.2)\n",
            "Requirement already satisfied: requests<3,>=2.27.0 in /usr/local/lib/python3.10/dist-packages (from tweepy) (2.32.3)\n",
            "Requirement already satisfied: requests-oauthlib<2,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from tweepy) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27.0->tweepy) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27.0->tweepy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27.0->tweepy) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27.0->tweepy) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "pip install tweepy\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tweepy\n",
        "\n",
        "consumer_key = 'Q1AFIkXkasespE028gfQ8BgVB'\n",
        "consumer_secret = 'OMHWRFMzJ00ppUibLx2z7jtmle0UoSBpkqJuvEyS6L3SE4AFiH'\n",
        "access_token = '1842502996724236288-OwCSdL7sW6689gry1hTVvZ3Hi1nfjl'\n",
        "access_token_secret = 'AVg4OKOr158EL5inkjYdyWcEfXmXiF52CZDbKHfRf3fm8'\n",
        "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "api = tweepy.API(auth)"
      ],
      "metadata": {
        "id": "zrrKIFHgNpWG"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "bearer_token = 'AAAAAAAAAAAAAAAAAAAAADzzwgEAAAAAwMSxNWZqGseTbz46PKzrbL3%2BDLA%3Dyo9AYT6tPZWiqoi0cV04Um0iMLXNzy5kTcKm9I8UWzON5vHmmQ'\n",
        "username = 'outfarsi'\n",
        "url = f\"https://api.twitter.com/2/tweets?ids={username}\"\n",
        "\n",
        "headers = {\n",
        "    \"Authorization\": f\"Bearer {bearer_token}\",\n",
        "    \"User-Agent\": \"v2UserLookupPython\"\n",
        "}\n",
        "\n",
        "response = requests.get(url, headers=headers)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    tweets = response.json()\n",
        "    for tweet in tweets.get('data', []):\n",
        "        print(tweet['text'])\n",
        "else:\n",
        "    print(f\"Error: {response.status_code} - {response.text}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NeDB8aa4NtWU",
        "outputId": "f51ef8a9-9ee5-47fc-a355-b0d16f5d814e"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: 400 - {\"errors\":[{\"parameters\":{\"ids\":[\"outfarsi\"]},\"message\":\"The `ids` query parameter value [outfarsi] is not valid\"}],\"title\":\"Invalid Request\",\"detail\":\"One or more parameters to your request was invalid.\",\"type\":\"https://api.twitter.com/2/problems/invalid-request\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---------------------------------------------------------------------------------------------\n",
        "====================================================================================="
      ],
      "metadata": {
        "id": "nwoarVkxmV5q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "consumer_key = 'U3XZAxCSN2bTnfyHxLoS8BiHZ'\n",
        "consumer_secret = 'x13lfOPCoDVSV6Oa8XqpbhZuKAnSQT5wCCZhle10GTxchcekB2'\n",
        "access_token = '1840472506894848000-o9YObo9yxCYdS0cpHbwFRTAX8Fv67g'\n",
        "access_token_secret = '5KrinLYbQv7ZKTt4KKRQ3IZtuJcLO3zoMEVcDYGEuyTAn'\n",
        "bearer_token = 'AAAAAAAAAAAAAAAAAAAAABH0wgEAAAAA%2BNHzeKYr7KKBgp6FRECs8mQ0wt0%3DCE39OhbjVlMXg2kO0yTpPQnGCxnoMazVvyUmNK2TkrjbR0m7Ih'\n",
        "username = 'outfarsi'\n",
        "\n",
        "# Step 1: Get the user ID from the username\n",
        "user_url = f\"https://api.twitter.com/2/users/by/username/{username}\"\n",
        "\n",
        "headers = {\n",
        "    \"Authorization\": f\"Bearer {bearer_token}\",\n",
        "}\n",
        "\n",
        "response = requests.get(user_url, headers=headers)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    user_data = response.json()\n",
        "    user_id = user_data['data']['id']\n",
        "    print(f\"User ID for {username}: {user_id}\")\n",
        "else:\n",
        "    print(f\"Error: {response.status_code} - {response.text}\")\n"
      ],
      "metadata": {
        "id": "2hgtaDrrTYwL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Fetch tweets using the user ID\n",
        "tweets_url = f\"https://api.twitter.com/2/users/{user_id}/tweets\"\n",
        "\n",
        "user_id = \"551857757\"\n",
        "\n",
        "tweets_response = requests.get(tweets_url, headers=headers)\n",
        "\n",
        "if tweets_response.status_code == 200:\n",
        "    tweets = tweets_response.json()\n",
        "    for tweet in tweets.get('data', []):\n",
        "        print(tweet['text'])\n",
        "else:\n",
        "    print(f\"Error: {tweets_response.status_code} - {tweets_response.text}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZU1YzewITwIG",
        "outputId": "49e56bd5-7e6f-44e5-e004-7aa53b1c8c41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RT @myfootkin: کریسمس برای ما نیست، ولنتاین برای ما نیست، هالووین برای ما نیست، هر چیزی توش جشن و شادی باشه برای ما نیست. \n",
            "فقط محرم و صفر و…\n",
            "RT @myfootkin: ۱۵۰ روز شد که حسین ر بخاطر یک نقطه زندانی کردن.\n",
            "ما هروز صدایت میشویم و هروز متنفر تر از آخوند.\n",
            "#حسین_شنبه‌زاده \n",
            "#IRGCterrori…\n",
            "#فوری\n",
            "دولت آلمان از شهروندانش خواست اگر میخواهند گروگان گرفته نشوند به ایران سفر نکنند.\n",
            "#IRGCterrorists‌\n",
            "* شورای عالی امنیت ملی\n",
            "#فوری \n",
            "نیویورک تایمز:\n",
            "خامنه ای در جلسه شورای امنیت به فرماندهان نظامی دستور حمله تلافی جویانه به اسرائیل را صادر کرده است، زیرا خسارات وارده از حمله اسرائیل چشمگیر بوده است.\n",
            "#IRGCterrorists‌\n",
            "#فوری\n",
            "پنتاگون به ارتش اسرائیل هشدار داد آمادگی لازم را انجام دهد برای حمله احتمالی امشب توسط جمهوری اسلامی.\n",
            "#IRGCterrorists‌\n",
            "#فوری\n",
            "آلمان در سطح وزیر امور خارجه از اتحادیه اروپا خواست که سپاه پاسداران را در لیست تروریستی قرار دهند و تمام کنسولگریهای رژیم در آلمان بسته شدند.\n",
            "#IRGCterrorists‌\n",
            "#آمریکا خطاب به سازمان ملل :\n",
            "کوچکترین حمله ایران به اثنیروهای آمریکایی و یا اسرائیل منجر به بزرگترین برخورد نظامی با جمهوری اسلامی خواهد شد.\n",
            "سپاه دیگر توان دفاعی از خود را ندارد.\n",
            "#IRGCterrorists‌\n",
            "RT @myfootkin: اسرائیل در ازای حمله به خانه ناتانیاهو قراره دوباره اقدام نظامی بکنه در خاک ایران به به.\n",
            "#IRGCterrorists‌ https://t.co/UrMH0…\n",
            "#فوری\n",
            "کانال سیزده اسرائیل:\n",
            "ارتش قرار است یک پاسخ کوبنده دیگره به جمهوری اسلامی بدهد.\n",
            "#IRGCterrorists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "consumer_key = 'U3XZAxCSN2bTnfyHxLoS8BiHZ'\n",
        "consumer_secret = 'x13lfOPCoDVSV6Oa8XqpbhZuKAnSQT5wCCZhle10GTxchcekB2'\n",
        "access_token = '1840472506894848000-o9YObo9yxCYdS0cpHbwFRTAX8Fv67g'\n",
        "access_token_secret = '5KrinLYbQv7ZKTt4KKRQ3IZtuJcLO3zoMEVcDYGEuyTAn'\n",
        "bearer_token = 'AAAAAAAAAAAAAAAAAAAAABH0wgEAAAAA%2BNHzeKYr7KKBgp6FRECs8mQ0wt0%3DCE39OhbjVlMXg2kO0yTpPQnGCxnoMazVvyUmNK2TkrjbR0m7Ih'\n",
        "\n",
        "# Your Twitter API Bearer Token\n",
        "headers = {\n",
        "    \"Authorization\": f\"Bearer {bearer_token}\"\n",
        "}\n",
        "\n",
        "# Step 1: Fetch tweets using the user ID\n",
        "user_id = \"1256864700647845888\"  # Replace with the specific user ID\n",
        "user_id = \"551857757\"\n",
        "\n",
        "\n",
        "tweets_url = f\"https://api.twitter.com/2/users/{user_id}/tweets\"\n",
        "\n",
        "tweets_response = requests.get(tweets_url, headers=headers)\n",
        "\n",
        "if tweets_response.status_code == 200:\n",
        "    tweets = tweets_response.json()\n",
        "    for tweet in tweets.get('data', []):\n",
        "        print(f\"Tweet: {tweet['text']} (ID: {tweet['id']})\")\n",
        "\n",
        "        # Step 2: Fetch replies to the specific tweet\n",
        "        tweet_id = tweet['id']  # Get the ID of the current tweet\n",
        "        replies_url = f\"https://api.twitter.com/2/tweets/{tweet_id}/replies\"\n",
        "\n",
        "        replies_response = requests.get(replies_url, headers=headers)\n",
        "\n",
        "        if replies_response.status_code == 200:\n",
        "            replies = replies_response.json()\n",
        "            print(\"Replies:\")\n",
        "            for reply in replies.get('data', []):\n",
        "                print(f\"- {reply['text']}\")\n",
        "        else:\n",
        "            print(f\"Error fetching replies: {replies_response.status_code} - {replies_response.text}\")\n",
        "else:\n",
        "    print(f\"Error fetching tweets: {tweets_response.status_code} - {tweets_response.text}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qe40R4sLjYPU",
        "outputId": "6cd64a49-cab7-4cf8-c82c-4224b5ed0363"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tweet: @ishararee @lili__far شما‌ هم قحبه شدید ؟ \n",
            "ترسناک‌ترین موجودی که یه آخوند میتونه ببینه (ID: 1852461975793508528)\n",
            "Error fetching replies: 404 - \n",
            "Tweet: @nouriseyamak داداش موجود نری که واژن تحت سلطه‌اش رو با ۲ تا نر دیگه سهیم میشه چیزی برای از دست دادن نداره (ID: 1852461020242935935)\n",
            "Error fetching replies: 404 - \n",
            "Tweet: RT @lel3ron: کس‌‌‌ مادرت میده من نمیگم میام ننه‌تو میکنم کسکش (ID: 1852459798517690373)\n",
            "Error fetching replies: 404 - \n",
            "Tweet: @erfansefidi زاییدیش یا گاییدیش ؟ (ID: 1852457526924574959)\n",
            "Error fetching replies: 404 - \n",
            "Tweet: کیر تو کس خوار‌ مادر بدخواهای خانم دوم از چپ ردیف پایین https://t.co/d4vQobvOpl (ID: 1852442197343207822)\n",
            "Error fetching replies: 404 - \n",
            "Tweet: RT @currentlynumbN: توئیتر بس دی دا\n",
            "هامیا خوش گچیر من ده مال کیمین ایشلیرم (ID: 1852408892816302431)\n",
            "Error fetching replies: 404 - \n",
            "Tweet: RT @GarbageHuman24: https://t.co/g7RzPaPlUy (ID: 1852366654816031167)\n",
            "Error fetching replies: 404 - \n",
            "Tweet: روانشناسا میگن کیرت تو این زندگی (ID: 1852353413238886811)\n",
            "Error fetching replies: 404 - \n",
            "Tweet: No kose madaret https://t.co/osmgCcBPHH (ID: 1852344064089178430)\n",
            "Error fetching replies: 404 - \n",
            "Tweet: @ThePadrepr Em Lamar Future (ID: 1852342798302765158)\n",
            "Error fetching replies: 404 - \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import csv\n",
        "\n",
        "# Your Twitter API Bearer Token\n",
        "consumer_key = 'U3XZAxCSN2bTnfyHxLoS8BiHZ'\n",
        "consumer_secret = 'x13lfOPCoDVSV6Oa8XqpbhZuKAnSQT5wCCZhle10GTxchcekB2'\n",
        "access_token = '1840472506894848000-o9YObo9yxCYdS0cpHbwFRTAX8Fv67g'\n",
        "access_token_secret = '5KrinLYbQv7ZKTt4KKRQ3IZtuJcLO3zoMEVcDYGEuyTAn'\n",
        "bearer_token = 'AAAAAAAAAAAAAAAAAAAAABH0wgEAAAAA%2BNHzeKYr7KKBgp6FRECs8mQ0wt0%3DCE39OhbjVlMXg2kO0yTpPQnGCxnoMazVvyUmNK2TkrjbR0m7Ih'\n",
        "\n",
        "consumer_key = 'blbcoMIZ5uCxAVSPzhyPb6zZy'\n",
        "consumer_secret = 'gmBI5znemhDOAGC24tMSMd2PzZJmaJrYfOg27zGYnyajUvB2qH'\n",
        "bearer_token = 'AAAAAAAAAAAAAAAAAAAAAHnzwgEAAAAAh%2FPgFJjdh7WmiEnzBCEGbu4F1Vg%3Di7Vd8mNuLIY7NFAI5UlExwJk9YSMS0pRv74h64zCHwfS7Jv56A'\n",
        "access_token = '1852584711966605312-zgsUN8CZXw7OKE1lFgMa27W7lJuh4e'\n",
        "access_token_secret = 'Fvqyz7BDeqVDIhdsb3POsEb637XJz0WaaqXgKna1KxKuX'\n",
        "\n",
        "headers = {\n",
        "    \"Authorization\": f\"Bearer {bearer_token}\"\n",
        "}\n",
        "\n",
        "# Step 1: Fetch tweets using the user ID\n",
        "#user_id = \"1256864700647845888\"  # Replace with the specific user ID\n",
        "# user_id = \"551857757\"  # Uncomment this if you want to use this user ID\n",
        "user_id = \"1455134942086713344\"  # Replace with the specific user ID\n",
        "\n",
        "tweets_url = f\"https://api.twitter.com/2/users/{user_id}/tweets\"\n",
        "\n",
        "tweets_response = requests.get(tweets_url, headers=headers)\n",
        "\n",
        "# List to hold tweet data\n",
        "tweets_data = []\n",
        "\n",
        "if tweets_response.status_code == 200:\n",
        "    tweets = tweets_response.json()\n",
        "    for tweet in tweets.get('data', []):\n",
        "        tweet_text = tweet['text']\n",
        "        tweet_id = tweet['id']\n",
        "        print(f\"Tweet: {tweet_text} (ID: {tweet_id})\")\n",
        "\n",
        "        # Step 2: Fetch replies to the specific tweet\n",
        "        replies_url = f\"https://api.twitter.com/2/tweets/{tweet_id}/replies\"\n",
        "        replies_response = requests.get(replies_url, headers=headers)\n",
        "\n",
        "        replies_texts = []\n",
        "        if replies_response.status_code == 200:\n",
        "            replies = replies_response.json()\n",
        "            for reply in replies.get('data', []):\n",
        "                replies_texts.append(reply['text'])\n",
        "        else:\n",
        "            print(f\"Error fetching replies: {replies_response.status_code} - {replies_response.text}\")\n",
        "\n",
        "        # Append tweet and its replies to the data list\n",
        "        tweets_data.append({'Tweet ID': tweet_id, 'Tweet Text': tweet_text, 'Replies': replies_texts})\n",
        "\n",
        "else:\n",
        "    print(f\"Error fetching tweets: {tweets_response.status_code} - {tweets_response.text}\")\n",
        "\n",
        "# Step 3: Save the tweets and replies to a CSV file\n",
        "csv_file_path = '/content/tweets_replies.csv'\n",
        "with open(csv_file_path, mode='w', newline='', encoding='utf-8') as csv_file:\n",
        "    fieldnames = ['Tweet ID', 'Tweet Text', 'Replies']\n",
        "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
        "\n",
        "    writer.writeheader()\n",
        "    for tweet in tweets_data:\n",
        "        writer.writerow({\n",
        "            'Tweet ID': tweet['Tweet ID'],\n",
        "            'Tweet Text': tweet['Tweet Text'],\n",
        "            'Replies': '; '.join(tweet['Replies'])  # Joining replies into a single string\n",
        "        })\n",
        "\n",
        "print(f\"Tweets and replies saved to {csv_file_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbrY16MayRaE",
        "outputId": "d58e072e-9a90-4019-e866-5d465cad4088"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error fetching tweets: 429 - {\"title\":\"Too Many Requests\",\"detail\":\"Too Many Requests\",\"type\":\"about:blank\",\"status\":429}\n",
            "Tweets and replies saved to /content/tweets_replies.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandas scikit-learn tensorflow keras\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RfPDZFdXlzBI",
        "outputId": "629a1601-8ded-4883-e278-aadcd3051117"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.9.3)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.13.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.6)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('/content/farsi_words.csv')\n",
        "\n",
        "# Split data into features and labels\n",
        "X = data['word']\n",
        "y = data['label']\n",
        "\n",
        "# Convert labels to binary (0 for inappropriate, 1 for appropriate)\n",
        "y = y.map({'inappropriate': 0, 'appropriate': 1})\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "6lLregVTmPTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Vectorize the words\n",
        "vectorizer = CountVectorizer()\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "X_test_vectorized = vectorizer.transform(X_test)\n"
      ],
      "metadata": {
        "id": "ROE25U_OmkZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Initialize and train the model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train_vectorized, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test_vectorized)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqjEudj0mlHE",
        "outputId": "c7f349e6-d75e-4fe8-c8c4-a5f509d7fac1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67         1\n",
            "           1       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.50         2\n",
            "   macro avg       0.25      0.50      0.33         2\n",
            "weighted avg       0.25      0.50      0.33         2\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, Flatten\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Prepare the data for the neural network\n",
        "X_train_sequences = vectorizer.transform(X_train).toarray()\n",
        "X_test_sequences = vectorizer.transform(X_test).toarray()\n",
        "\n",
        "# Define the model\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_shape=(X_train_sequences.shape[1],)))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train_sequences, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_test_sequences, y_test)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRTwqksLmpUl",
        "outputId": "f692a359-9996-4504-b8a3-e4a6640d7fa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.6667 - loss: 0.6695 - val_accuracy: 1.0000 - val_loss: 0.6185\n",
            "Epoch 2/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 334ms/step - accuracy: 0.6667 - loss: 0.6646 - val_accuracy: 1.0000 - val_loss: 0.6181\n",
            "Epoch 3/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.6667 - loss: 0.6598 - val_accuracy: 1.0000 - val_loss: 0.6176\n",
            "Epoch 4/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.6667 - loss: 0.6549 - val_accuracy: 1.0000 - val_loss: 0.6172\n",
            "Epoch 5/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.6667 - loss: 0.6501 - val_accuracy: 1.0000 - val_loss: 0.6167\n",
            "Epoch 6/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.6667 - loss: 0.6453 - val_accuracy: 1.0000 - val_loss: 0.6162\n",
            "Epoch 7/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 0.6405 - val_accuracy: 1.0000 - val_loss: 0.6157\n",
            "Epoch 8/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.6358 - val_accuracy: 1.0000 - val_loss: 0.6151\n",
            "Epoch 9/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.6310 - val_accuracy: 1.0000 - val_loss: 0.6146\n",
            "Epoch 10/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.6264 - val_accuracy: 1.0000 - val_loss: 0.6141\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5000 - loss: 0.6932\n",
            "Accuracy: 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "model.save('farsi_word_classifier.h5')\n",
        "\n",
        "# Load the model\n",
        "from keras.models import load_model\n",
        "loaded_model = load_model('farsi_word_classifier.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiCFxKTFmrYA",
        "outputId": "e31c6fe9-4f38-44ec-82a7-186e82085c74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_word(word):\n",
        "    word_vectorized = vectorizer.transform([word]).toarray()\n",
        "    prediction = loaded_model.predict(word_vectorized)\n",
        "    return \"Appropriate\" if prediction[0][0] >= 0.5 else \"Inappropriate\"\n",
        "\n",
        "# Test the prediction function\n",
        "print(predict_word(\"خوب\"))  # Should output \"Appropriate\"\n",
        "print(predict_word(\"فحش\"))  # Should output \"Inappropriate\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-u-hqotKms-R",
        "outputId": "e746fd87-f41d-44a9-c3fa-d7406faf83ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "Inappropriate\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "Inappropriate\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---------------------------------------------------------------\n",
        "================================================================="
      ],
      "metadata": {
        "id": "f7xadf29mQ20"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import joblib\n",
        "\n",
        "# Load the dataset (make sure to provide the correct path to your CSV file)\n",
        "data = pd.read_csv('/content/farsi_inappropriate_words.csv')\n",
        "\n",
        "# Check the data\n",
        "print(data.head())\n",
        "print(data.info())\n",
        "\n",
        "# Split data into features and labels\n",
        "X = data['word']\n",
        "y = data['label']\n",
        "\n",
        "# Convert labels to binary (0 for inappropriate)\n",
        "y = y.map({'inappropriate': 0})\n",
        "\n",
        "# Since we only have inappropriate words, we can assume all others are appropriate\n",
        "# Create an array of appropriate labels\n",
        "appropriate_words = ['خوب', 'عالی', 'مهربان', 'سالم', 'دوست', 'محبت', 'زیبا']  # Add more appropriate words if needed\n",
        "appropriate_labels = [1] * len(appropriate_words)  # Label for appropriate words\n",
        "\n",
        "# Combine both lists\n",
        "X = X.tolist() + appropriate_words\n",
        "y = y.tolist() + appropriate_labels  # Append appropriate labels\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Vectorize the words\n",
        "vectorizer = CountVectorizer()\n",
        "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "X_test_vectorized = vectorizer.transform(X_test)\n",
        "\n",
        "# Train a Logistic Regression model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train_vectorized, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test_vectorized)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Define the prediction function\n",
        "def predict_word(word):\n",
        "    # Transform the word into the same format used during training\n",
        "    word_vectorized = vectorizer.transform([word])\n",
        "\n",
        "    # Get the prediction\n",
        "    prediction = model.predict(word_vectorized)\n",
        "\n",
        "    return \"Inappropriate\" if prediction[0] == 0 else \"Appropriate\"\n",
        "\n",
        "# Test the prediction function\n",
        "print(predict_word(\"خر\"))   # Should output \"Inappropriate\"\n",
        "print(predict_word(\"گاو\"))   # Should output \"Inappropriate\"\n",
        "print(predict_word(\"مهربان\"))   # Should output \"Appropriate\"\n",
        "print(predict_word(\"عالی\"))      # Should output \"Appropriate\"\n",
        "print(predict_word(\"نفهم\"))    # Should output \"Inappropriate\"\n",
        "print(predict_word(\"لجن\"))      # Should output \"Inappropriate\"\n",
        "\n",
        "\n",
        "# Optionally, save the model and vectorizer\n",
        "joblib.dump(model, 'farsi_word_classifier.pkl')\n",
        "joblib.dump(vectorizer, 'farsi_vectorizer.pkl')\n",
        "\n",
        "# Load the model and vectorizer if needed\n",
        "# model = joblib.load('farsi_word_classifier.pkl')\n",
        "# vectorizer = joblib.load('farsi_vectorizer.pkl')\n"
      ],
      "metadata": {
        "id": "0Zr546ecof4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "\n",
        "# Load the inappropriate words\n",
        "inappropriate_words_df = pd.read_csv('farsi_inappropriate_words.csv')\n",
        "inappropriate_words = inappropriate_words_df['word'].tolist()  # Assuming the column with words is named 'word'\n",
        "\n",
        "# Sample dataset to classify (You can expand this with more examples)\n",
        "# Example sentences for testing - replace with your actual data\n",
        "sentences = [\n",
        "    \"چه زیبا و دلنشین است بسیار لذت بردم.\",  # This is an appropriate sentence.\n",
        "    \"عوضی آشغال لعنتی \" + inappropriate_words[0],  # Inappropriate sentence.\n",
        "    \"این یک متن دیگر است.\",  # Another appropriate sentence.\n",
        "    \"نمی‌خواهم از کلمات ناپسند استفاده کنم.\",  # Another appropriate sentence.\n",
        "    \"خیلی کثافت هستی دیوانه ی لجن\" + inappropriate_words[1]  # Another inappropriate sentence.\n",
        "]\n",
        "\n",
        "# Create labels: 1 for inappropriate, 0 for appropriate\n",
        "labels = [0, 1, 0, 0, 1]  # Adjust labels accordingly based on your sentences\n",
        "\n",
        "# Convert to DataFrame\n",
        "data = pd.DataFrame({'text': sentences, 'label': labels})\n",
        "\n",
        "# Prepare the feature extraction\n",
        "count_vect = CountVectorizer()\n",
        "x_train_counts = count_vect.fit_transform(data['text'])\n",
        "\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "x_train_tfidf = tfidf_transformer.fit_transform(x_train_counts)\n",
        "\n",
        "# Split the dataset\n",
        "train_x, test_x, train_y, test_y = train_test_split(x_train_tfidf, data['label'], test_size=0.3)\n",
        "\n",
        "# Train the model\n",
        "clf = MultinomialNB().fit(train_x, train_y)\n",
        "\n",
        "# Make predictions\n",
        "y_score = clf.predict(test_x)\n",
        "\n",
        "# Calculate accuracy\n",
        "n_right = sum(y_score == test_y)\n",
        "accuracy = (n_right / float(len(test_y))) * 100\n",
        "\n",
        "print(\"Accuracy: %.2f%%\" % accuracy)\n",
        "\n",
        "# Example to predict on new text\n",
        "new_texts = [\"این متن جدید است.\", \"متن ناپسند: \" + inappropriate_words[2]]\n",
        "new_text_counts = count_vect.transform(new_texts)\n",
        "new_text_tfidf = tfidf_transformer.transform(new_text_counts)\n",
        "predictions = clf.predict(new_text_tfidf)\n",
        "\n",
        "for text, prediction in zip(new_texts, predictions):\n",
        "    print(f\"Text: '{text}' - Prediction: {'Inappropriate' if prediction == 1 else 'Appropriate'}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "3TTz3Ga1uVTt",
        "outputId": "1caa36ea-c580-44fb-a779-44d8d80ae532"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'farsi_inappropriate_words.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-143-1ab12d4a5aaf>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Load the inappropriate words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0minappropriate_words_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'farsi_inappropriate_words.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0minappropriate_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minappropriate_words_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'word'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Assuming the column with words is named 'word'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'farsi_inappropriate_words.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install PHP\n",
        "!apt-get install -y php\n",
        "\n",
        "# Install Composer\n",
        "!curl -sS https://getcomposer.org/installer | php -- --install-dir=/usr/local/bin --filename=composer\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dI-DBPF02BQY",
        "outputId": "b4cb1f67-a41c-43a5-f3ca-0ce9e6396c7e"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "php is already the newest version (2:8.1+92ubuntu1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n",
            "All settings correct for using Composer\n",
            "Downloading...\n",
            "\n",
            "Composer (version 2.8.2) successfully installed to: /usr/local/bin/composer\n",
            "Use it: php /usr/local/bin/composer\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new directory for your project\n",
        "!mkdir myproject\n",
        "%cd myproject\n",
        "\n",
        "# Initialize Composer and require the package\n",
        "!composer require amirshnll/persian-swear-words\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHSJ0PmV4kW_",
        "outputId": "1b92fa44-78f6-4eb4-8706-8d25cfa3f9cb"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/myproject/myproject/myproject/myproject\n",
            "\u001b[32mNo composer.json in current directory, do you want to use the one at /content/myproject?\u001b[39m [\u001b[33mY,n\u001b[39m]? y\n",
            "\u001b[32mAlways want to use the parent dir? Use \"composer config --global use-parent-dir true\" to change the default.\u001b[39m\n",
            "\u001b[32m./composer.json has been updated\u001b[39m\n",
            "\u001b[32mRunning composer update amirshnll/persian-swear-words\u001b[39m\n",
            "\u001b[32mLoading composer repositories with package information\u001b[39m\n",
            "\u001b[32mUpdating dependencies\u001b[39m\n",
            "Nothing to modify in lock file\n",
            "\u001b[32mWriting lock file\u001b[39m\n",
            "\u001b[32mInstalling dependencies from lock file (including require-dev)\u001b[39m\n",
            "Nothing to install, update or remove\n",
            "\u001b[32mGenerating autoload files\u001b[39m\n",
            "\u001b[32m1 package you are using is looking for funding.\u001b[39m\n",
            "\u001b[32mUse the `composer fund` command to find out more!\u001b[39m\n",
            "\u001b[32mNo security vulnerability advisories found.\u001b[39m\n",
            "Using version \u001b[32m^3.0\u001b[39m for \u001b[32mamirshnll/persian-swear-words\u001b[39m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Node.js\n",
        "!apt-get install -y nodejs npm\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EiScyp5P43VI",
        "outputId": "d07e2f1a-da69-4bd2-9625-45d4d406cfa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  gyp javascript-common libc-ares2 libjs-events libjs-highlight.js libjs-inherits\n",
            "  libjs-is-typedarray libjs-psl libjs-source-map libjs-sprintf-js libjs-typedarray-to-buffer\n",
            "  libnode-dev libnode72 libnotify-bin libnotify4 libuv1-dev node-abab node-abbrev node-agent-base\n",
            "  node-ansi-regex node-ansi-styles node-ansistyles node-aproba node-archy node-are-we-there-yet\n",
            "  node-argparse node-arrify node-asap node-asynckit node-balanced-match node-brace-expansion\n",
            "  node-builtins node-cacache node-chalk node-chownr node-clean-yaml-object node-cli-table\n",
            "  node-clone node-color-convert node-color-name node-colors node-columnify node-combined-stream\n",
            "  node-commander node-console-control-strings node-copy-concurrently node-core-util-is\n",
            "  node-coveralls node-cssom node-cssstyle node-debug node-decompress-response node-defaults\n",
            "  node-delayed-stream node-delegates node-depd node-diff node-encoding node-end-of-stream\n",
            "  node-err-code node-escape-string-regexp node-esprima node-events node-fancy-log node-fetch\n",
            "  node-foreground-child node-form-data node-fs-write-stream-atomic node-fs.realpath\n",
            "  node-function-bind node-gauge node-get-stream node-glob node-got node-graceful-fs node-growl\n",
            "  node-gyp node-has-flag node-has-unicode node-hosted-git-info node-https-proxy-agent\n",
            "  node-iconv-lite node-iferr node-imurmurhash node-indent-string node-inflight node-inherits\n",
            "  node-ini node-ip node-ip-regex node-is-buffer node-is-plain-obj node-is-typedarray node-isarray\n",
            "  node-isexe node-js-yaml node-jsdom node-json-buffer node-json-parse-better-errors node-jsonparse\n",
            "  node-kind-of node-lcov-parse node-lodash-packages node-log-driver node-lowercase-keys\n",
            "  node-lru-cache node-mime node-mime-types node-mimic-response node-minimatch node-minimist\n",
            "  node-minipass node-mkdirp node-move-concurrently node-ms node-mute-stream node-negotiator\n",
            "  node-nopt node-normalize-package-data node-npm-bundled node-npm-package-arg node-npmlog\n",
            "  node-object-assign node-once node-opener node-osenv node-p-cancelable node-p-map\n",
            "  node-path-is-absolute node-process-nextick-args node-promise-inflight node-promise-retry\n",
            "  node-promzard node-psl node-pump node-punycode node-quick-lru node-read node-read-package-json\n",
            "  node-readable-stream node-resolve node-retry node-rimraf node-run-queue node-safe-buffer\n",
            "  node-semver node-set-blocking node-signal-exit node-slash node-slice-ansi node-source-map\n",
            "  node-source-map-support node-spdx-correct node-spdx-exceptions node-spdx-expression-parse\n",
            "  node-spdx-license-ids node-sprintf-js node-ssri node-stack-utils node-stealthy-require\n",
            "  node-string-decoder node-string-width node-strip-ansi node-supports-color node-tap\n",
            "  node-tap-mocha-reporter node-tap-parser node-tar node-text-table node-time-stamp node-tmatch\n",
            "  node-tough-cookie node-typedarray-to-buffer node-unique-filename node-universalify\n",
            "  node-util-deprecate node-validate-npm-package-license node-validate-npm-package-name\n",
            "  node-wcwidth.js node-webidl-conversions node-whatwg-fetch node-which node-wide-align node-wrappy\n",
            "  node-write-file-atomic node-ws node-yallist nodejs-doc\n",
            "Suggested packages:\n",
            "  libjs-angularjs gnome-shell | notification-daemon node-nyc\n",
            "The following NEW packages will be installed:\n",
            "  gyp javascript-common libc-ares2 libjs-events libjs-highlight.js libjs-inherits\n",
            "  libjs-is-typedarray libjs-psl libjs-source-map libjs-sprintf-js libjs-typedarray-to-buffer\n",
            "  libnode-dev libnode72 libnotify-bin libnotify4 libuv1-dev node-abab node-abbrev node-agent-base\n",
            "  node-ansi-regex node-ansi-styles node-ansistyles node-aproba node-archy node-are-we-there-yet\n",
            "  node-argparse node-arrify node-asap node-asynckit node-balanced-match node-brace-expansion\n",
            "  node-builtins node-cacache node-chalk node-chownr node-clean-yaml-object node-cli-table\n",
            "  node-clone node-color-convert node-color-name node-colors node-columnify node-combined-stream\n",
            "  node-commander node-console-control-strings node-copy-concurrently node-core-util-is\n",
            "  node-coveralls node-cssom node-cssstyle node-debug node-decompress-response node-defaults\n",
            "  node-delayed-stream node-delegates node-depd node-diff node-encoding node-end-of-stream\n",
            "  node-err-code node-escape-string-regexp node-esprima node-events node-fancy-log node-fetch\n",
            "  node-foreground-child node-form-data node-fs-write-stream-atomic node-fs.realpath\n",
            "  node-function-bind node-gauge node-get-stream node-glob node-got node-graceful-fs node-growl\n",
            "  node-gyp node-has-flag node-has-unicode node-hosted-git-info node-https-proxy-agent\n",
            "  node-iconv-lite node-iferr node-imurmurhash node-indent-string node-inflight node-inherits\n",
            "  node-ini node-ip node-ip-regex node-is-buffer node-is-plain-obj node-is-typedarray node-isarray\n",
            "  node-isexe node-js-yaml node-jsdom node-json-buffer node-json-parse-better-errors node-jsonparse\n",
            "  node-kind-of node-lcov-parse node-lodash-packages node-log-driver node-lowercase-keys\n",
            "  node-lru-cache node-mime node-mime-types node-mimic-response node-minimatch node-minimist\n",
            "  node-minipass node-mkdirp node-move-concurrently node-ms node-mute-stream node-negotiator\n",
            "  node-nopt node-normalize-package-data node-npm-bundled node-npm-package-arg node-npmlog\n",
            "  node-object-assign node-once node-opener node-osenv node-p-cancelable node-p-map\n",
            "  node-path-is-absolute node-process-nextick-args node-promise-inflight node-promise-retry\n",
            "  node-promzard node-psl node-pump node-punycode node-quick-lru node-read node-read-package-json\n",
            "  node-readable-stream node-resolve node-retry node-rimraf node-run-queue node-safe-buffer\n",
            "  node-semver node-set-blocking node-signal-exit node-slash node-slice-ansi node-source-map\n",
            "  node-source-map-support node-spdx-correct node-spdx-exceptions node-spdx-expression-parse\n",
            "  node-spdx-license-ids node-sprintf-js node-ssri node-stack-utils node-stealthy-require\n",
            "  node-string-decoder node-string-width node-strip-ansi node-supports-color node-tap\n",
            "  node-tap-mocha-reporter node-tap-parser node-tar node-text-table node-time-stamp node-tmatch\n",
            "  node-tough-cookie node-typedarray-to-buffer node-unique-filename node-universalify\n",
            "  node-util-deprecate node-validate-npm-package-license node-validate-npm-package-name\n",
            "  node-wcwidth.js node-webidl-conversions node-whatwg-fetch node-which node-wide-align node-wrappy\n",
            "  node-write-file-atomic node-ws node-yallist nodejs nodejs-doc npm\n",
            "0 upgraded, 190 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 18.8 MB of archives.\n",
            "After this operation, 90.4 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 gyp all 0.1+20210831gitd6c5dd5-5 [238 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 javascript-common all 11+nmu1 [5,936 B]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libjs-events all 3.3.0+~3.0.0-2 [9,734 B]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libjs-highlight.js all 9.18.5+dfsg1-1 [367 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libjs-is-typedarray all 1.0.0-4 [3,804 B]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libjs-psl all 1.8.0+ds-6 [76.3 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libjs-sprintf-js all 1.1.2+ds1+~1.1.2-1 [12.8 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libjs-typedarray-to-buffer all 4.0.0-2 [4,658 B]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libuv1-dev amd64 1.43.0-1ubuntu0.1 [130 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libc-ares2 amd64 1.18.1-1ubuntu0.22.04.3 [45.1 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libnode72 amd64 12.22.9~dfsg-1ubuntu3.6 [10.8 MB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libnode-dev amd64 12.22.9~dfsg-1ubuntu3.6 [609 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libnotify4 amd64 0.7.9-3ubuntu5.22.04.1 [20.3 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libnotify-bin amd64 0.7.9-3ubuntu5.22.04.1 [7,560 B]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 nodejs amd64 12.22.9~dfsg-1ubuntu3.6 [122 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-abab all 2.0.5-2 [6,578 B]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-ms all 2.1.3+~cs0.7.31-2 [5,782 B]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-debug all 4.3.2+~cs4.1.7-1 [17.6 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-yallist all 4.0.0+~4.0.1-1 [8,322 B]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-lru-cache all 6.0.0+~5.1.1-1 [11.3 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-semver all 7.3.5+~7.3.8-1 [41.5 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-agent-base all 6.0.2+~cs5.4.2-1 [17.9 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-ansi-regex all 5.0.1-1 [4,984 B]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-ansistyles all 0.1.3-5 [4,546 B]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-aproba all 2.0.0-2 [5,620 B]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-delegates all 1.0.0-3 [4,280 B]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libjs-inherits all 2.0.4-4 [3,468 B]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-inherits all 2.0.4-4 [3,010 B]\n",
            "Get:29 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-core-util-is all 1.0.3-1 [4,066 B]\n",
            "Get:30 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-safe-buffer all 5.2.1+~cs2.1.2-2 [15.7 kB]\n",
            "Get:31 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-string-decoder all 1.3.0-5 [7,046 B]\n",
            "Get:32 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-process-nextick-args all 2.0.1-2 [3,730 B]\n",
            "Get:33 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-util-deprecate all 1.0.2-3 [4,202 B]\n",
            "Get:34 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-isarray all 2.0.5-3 [3,934 B]\n",
            "Get:35 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-readable-stream all 3.6.0+~cs3.0.0-1 [32.6 kB]\n",
            "Get:36 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-are-we-there-yet all 3.0.0+~1.1.0-1 [8,920 B]\n",
            "Get:37 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-arrify all 2.0.1-2 [3,610 B]\n",
            "Get:38 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-asap all 2.0.6+~2.0.0-1 [14.4 kB]\n",
            "Get:39 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-asynckit all 0.4.0-4 [10.6 kB]\n",
            "Get:40 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-builtins all 4.0.0-1 [3,860 B]\n",
            "Get:41 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-chownr all 2.0.0-1 [4,404 B]\n",
            "Get:42 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-fs.realpath all 1.0.0-2 [6,106 B]\n",
            "Get:43 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-wrappy all 1.0.2-2 [3,658 B]\n",
            "Get:44 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-once all 1.4.0-4 [4,708 B]\n",
            "Get:45 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-inflight all 1.0.6-2 [3,940 B]\n",
            "Get:46 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-balanced-match all 2.0.0-1 [4,910 B]\n",
            "Get:47 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-brace-expansion all 2.0.1-1 [7,458 B]\n",
            "Get:48 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-minimatch all 3.1.1+~3.0.5-1 [16.9 kB]\n",
            "Get:49 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-path-is-absolute all 2.0.0-2 [4,062 B]\n",
            "Get:50 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-glob all 7.2.1+~cs7.6.15-1 [131 kB]\n",
            "Get:51 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-graceful-fs all 4.2.4+repack-1 [12.5 kB]\n",
            "Get:52 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-mkdirp all 1.0.4+~1.0.2-1 [11.4 kB]\n",
            "Get:53 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-iferr all 1.0.2+~1.0.2-1 [4,610 B]\n",
            "Get:54 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-imurmurhash all 0.1.4+dfsg+~0.1.1-1 [8,510 B]\n",
            "Get:55 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-fs-write-stream-atomic all 1.0.10-5 [5,256 B]\n",
            "Get:56 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-rimraf all 3.0.2-1 [10.1 kB]\n",
            "Get:57 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-run-queue all 2.0.0-2 [5,092 B]\n",
            "Get:58 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-copy-concurrently all 1.0.5-8 [7,118 B]\n",
            "Get:59 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-move-concurrently all 1.0.1-4 [5,120 B]\n",
            "Get:60 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-escape-string-regexp all 4.0.0-2 [4,328 B]\n",
            "Get:61 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-indent-string all 4.0.0-2 [4,122 B]\n",
            "Get:62 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-p-map all 4.0.0+~3.1.0+~3.0.1-1 [8,058 B]\n",
            "Get:63 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-promise-inflight all 1.0.1+~1.0.0-1 [4,896 B]\n",
            "Get:64 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-ssri all 8.0.1-2 [19.6 kB]\n",
            "Get:65 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-unique-filename all 1.1.1+ds-1 [3,832 B]\n",
            "Get:66 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-cacache all 15.0.5+~cs13.9.21-3 [34.9 kB]\n",
            "Get:67 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-clean-yaml-object all 0.1.0-5 [4,718 B]\n",
            "Get:68 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-clone all 2.1.2-3 [8,344 B]\n",
            "Get:69 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-color-name all 1.1.4+~1.1.1-2 [6,076 B]\n",
            "Get:70 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-color-convert all 2.0.1-1 [10.2 kB]\n",
            "Get:71 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-colors all 1.4.0-3 [12.3 kB]\n",
            "Get:72 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-strip-ansi all 6.0.1-1 [4,184 B]\n",
            "Get:73 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-defaults all 1.0.3+~1.0.3-1 [4,288 B]\n",
            "Get:74 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-wcwidth.js all 1.0.2-1 [7,278 B]\n",
            "Get:75 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-columnify all 1.5.4+~1.5.1-1 [12.6 kB]\n",
            "Get:76 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-console-control-strings all 1.1.0-2 [5,428 B]\n",
            "Get:77 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-growl all 1.10.5-4 [7,064 B]\n",
            "Get:78 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-sprintf-js all 1.1.2+ds1+~1.1.2-1 [3,916 B]\n",
            "Get:79 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-argparse all 2.0.1-2 [33.2 kB]\n",
            "Get:80 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-esprima all 4.0.1+ds+~4.0.3-2 [69.3 kB]\n",
            "Get:81 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-js-yaml all 4.1.0+dfsg+~4.0.5-6 [62.7 kB]\n",
            "Get:82 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-lcov-parse all 1.0.0+20170612git80d039574ed9-5 [5,084 B]\n",
            "Get:83 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-log-driver all 1.2.7+git+20180219+bba1761737-7 [5,436 B]\n",
            "Get:84 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-is-plain-obj all 3.0.0-2 [3,994 B]\n",
            "Get:85 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-is-buffer all 2.0.5-2 [4,128 B]\n",
            "Get:86 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-kind-of all 6.0.3+dfsg-2 [8,628 B]\n",
            "Get:87 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-minimist all 1.2.5+~cs5.3.2-1 [9,434 B]\n",
            "Get:88 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-cssom all 0.4.4-3 [14.1 kB]\n",
            "Get:89 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-cssstyle all 2.3.0-2 [30.3 kB]\n",
            "Get:90 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-delayed-stream all 1.0.0-5 [5,464 B]\n",
            "Get:91 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-combined-stream all 1.0.8+~1.0.3-1 [7,432 B]\n",
            "Get:92 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-mime all 3.0.0+dfsg+~cs3.96.1-1 [38.1 kB]\n",
            "Get:93 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-mime-types all 2.1.33-1 [6,944 B]\n",
            "Get:94 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-form-data all 3.0.1-1 [13.4 kB]\n",
            "Get:95 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-events all 3.3.0+~3.0.0-2 [3,090 B]\n",
            "Get:96 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-https-proxy-agent all 5.0.0+~cs8.0.0-3 [16.4 kB]\n",
            "Get:97 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-iconv-lite all 0.6.3-2 [167 kB]\n",
            "Get:98 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-lodash-packages all 4.17.21+dfsg+~cs8.31.198.20210220-5 [166 kB]\n",
            "Get:99 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-stealthy-require all 1.1.1-5 [7,176 B]\n",
            "Get:100 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-punycode all 2.1.1-5 [9,902 B]\n",
            "Get:101 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-psl all 1.8.0+ds-6 [39.6 kB]\n",
            "Get:102 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-universalify all 2.0.0-3 [4,266 B]\n",
            "Get:103 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-tough-cookie all 4.0.0-2 [31.7 kB]\n",
            "Get:104 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-webidl-conversions all 7.0.0~1.1.0+~cs15.1.20180823-2 [27.5 kB]\n",
            "Get:105 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-commander all 9.0.0-2 [48.0 kB]\n",
            "Get:106 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-mute-stream all 0.0.8+~0.0.1-1 [6,448 B]\n",
            "Get:107 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-read all 1.0.7-3 [5,478 B]\n",
            "Get:108 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-ws all 8.5.0+~cs13.3.3-2 [49.5 kB]\n",
            "Get:109 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-jsdom all 19.0.0+~cs90.11.27-1 [446 kB]\n",
            "Get:110 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-fetch all 2.6.7+~2.5.12-1 [27.1 kB]\n",
            "Get:111 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-coveralls all 3.1.1-1 [14.2 kB]\n",
            "Get:112 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-mimic-response all 3.1.0-7 [5,430 B]\n",
            "Get:113 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-decompress-response all 6.0.0-2 [4,656 B]\n",
            "Get:114 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-diff all 5.0.0~dfsg+~5.0.1-3 [77.4 kB]\n",
            "Get:115 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-err-code all 2.0.3+dfsg-3 [4,918 B]\n",
            "Get:116 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-time-stamp all 2.2.0-1 [5,984 B]\n",
            "Get:117 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-fancy-log all 1.3.3+~cs1.3.1-2 [8,102 B]\n",
            "Get:118 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-signal-exit all 3.0.6+~3.0.1-1 [7,000 B]\n",
            "Get:119 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-foreground-child all 2.0.0-3 [5,542 B]\n",
            "Get:120 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-function-bind all 1.1.1+repacked+~1.0.3-1 [5,244 B]\n",
            "Get:121 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-has-unicode all 2.0.1-4 [3,948 B]\n",
            "Get:122 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-ansi-styles all 4.3.0+~4.2.0-1 [8,968 B]\n",
            "Get:123 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-slice-ansi all 5.0.0+~cs9.0.0-4 [8,044 B]\n",
            "Get:124 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-string-width all 4.2.3+~cs13.2.3-1 [11.4 kB]\n",
            "Get:125 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-wide-align all 1.1.3-4 [4,228 B]\n",
            "Get:126 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-gauge all 4.0.2-1 [16.3 kB]\n",
            "Get:127 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-end-of-stream all 1.4.4+~1.4.1-1 [5,340 B]\n",
            "Get:128 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-pump all 3.0.0-5 [5,160 B]\n",
            "Get:129 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-get-stream all 6.0.1-1 [7,324 B]\n",
            "Get:130 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-lowercase-keys all 2.0.0-2 [3,754 B]\n",
            "Get:131 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-json-buffer all 3.0.1-1 [3,812 B]\n",
            "Get:132 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-p-cancelable all 2.1.1-1 [7,358 B]\n",
            "Get:133 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-quick-lru all 5.1.1-1 [5,532 B]\n",
            "Get:134 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-got all 11.8.3+~cs58.7.37-1 [122 kB]\n",
            "Get:135 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-has-flag all 4.0.0-2 [4,228 B]\n",
            "Get:136 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-hosted-git-info all 4.0.2-1 [9,006 B]\n",
            "Get:137 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-ip all 1.1.5+~1.1.0-1 [8,140 B]\n",
            "Get:138 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-ip-regex all 4.3.0+~4.1.1-1 [5,254 B]\n",
            "Get:139 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-is-typedarray all 1.0.0-4 [2,072 B]\n",
            "Get:140 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-isexe all 2.0.0+~2.0.1-4 [6,102 B]\n",
            "Get:141 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-json-parse-better-errors all 1.0.2+~cs3.3.1-1 [7,328 B]\n",
            "Get:142 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-encoding all 0.1.13-2 [4,366 B]\n",
            "Get:143 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-jsonparse all 1.3.1-10 [8,060 B]\n",
            "Get:144 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-minipass all 3.1.6+~cs8.7.18-1 [32.9 kB]\n",
            "Get:145 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-npm-bundled all 1.1.2-1 [6,228 B]\n",
            "Get:146 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-osenv all 0.1.5+~0.1.0-1 [5,896 B]\n",
            "Get:147 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-validate-npm-package-name all 3.0.0-4 [5,058 B]\n",
            "Get:148 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-npm-package-arg all 8.1.5-1 [8,132 B]\n",
            "Get:149 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-object-assign all 4.1.1-6 [4,754 B]\n",
            "Get:150 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-opener all 1.5.2+~1.4.0-1 [6,000 B]\n",
            "Get:151 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-retry all 0.13.1+~0.12.1-1 [11.5 kB]\n",
            "Get:152 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-promise-retry all 2.0.1-2 [5,010 B]\n",
            "Get:153 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-promzard all 0.3.0-2 [6,888 B]\n",
            "Get:154 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-set-blocking all 2.0.0-2 [3,766 B]\n",
            "Get:155 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-slash all 3.0.0-2 [3,922 B]\n",
            "Get:156 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libjs-source-map all 0.7.0++dfsg2+really.0.6.1-9 [93.9 kB]\n",
            "Get:157 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-source-map all 0.7.0++dfsg2+really.0.6.1-9 [33.6 kB]\n",
            "Get:158 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-source-map-support all 0.5.21+ds+~0.5.4-1 [14.2 kB]\n",
            "Get:159 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-spdx-license-ids all 3.0.11-1 [7,306 B]\n",
            "Get:160 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-spdx-exceptions all 2.3.0-2 [3,978 B]\n",
            "Get:161 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-spdx-expression-parse all 3.0.1+~3.0.1-1 [7,658 B]\n",
            "Get:162 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-spdx-correct all 3.1.1-2 [5,476 B]\n",
            "Get:163 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-stack-utils all 2.0.5+~2.0.1-1 [9,368 B]\n",
            "Get:164 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-supports-color all 8.1.1+~8.1.1-1 [7,048 B]\n",
            "Get:165 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-tap-parser all 7.0.0+ds1-6 [19.4 kB]\n",
            "Get:166 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-tap-mocha-reporter all 3.0.7+ds-2 [39.2 kB]\n",
            "Get:167 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-text-table all 0.2.0-4 [4,762 B]\n",
            "Get:168 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-tmatch all 5.0.0-4 [6,002 B]\n",
            "Get:169 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-typedarray-to-buffer all 4.0.0-2 [2,242 B]\n",
            "Get:170 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-validate-npm-package-license all 3.0.4-2 [4,252 B]\n",
            "Get:171 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-whatwg-fetch all 3.6.2-5 [15.0 kB]\n",
            "Get:172 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-write-file-atomic all 3.0.3+~3.0.2-1 [7,690 B]\n",
            "Get:173 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 nodejs-doc all 12.22.9~dfsg-1ubuntu3.6 [2,411 kB]\n",
            "Get:174 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-abbrev all 1.1.1+~1.1.2-1 [5,784 B]\n",
            "Get:175 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-archy all 1.0.0-4 [4,728 B]\n",
            "Get:176 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-chalk all 4.1.2-1 [15.9 kB]\n",
            "Get:177 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-cli-table all 0.3.11+~cs0.13.3-1 [23.2 kB]\n",
            "Get:178 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-depd all 2.0.0-2 [10.5 kB]\n",
            "Get:179 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-nopt all 5.0.0-2 [11.3 kB]\n",
            "Get:180 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-npmlog all 6.0.1+~4.1.4-1 [9,968 B]\n",
            "Get:181 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-tar all 6.1.11+ds1+~cs6.0.6-1 [38.8 kB]\n",
            "Get:182 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-which all 2.0.2+~cs1.3.2-2 [7,374 B]\n",
            "Get:183 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-gyp all 8.4.1-1 [34.7 kB]\n",
            "Get:184 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-ini all 2.0.1-1 [6,528 B]\n",
            "Get:185 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-negotiator all 0.6.2+~0.6.1-1 [10.3 kB]\n",
            "Get:186 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-resolve all 1.20.0+~cs5.27.9-1 [20.7 kB]\n",
            "Get:187 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-normalize-package-data all 3.0.3+~2.4.1-1 [12.8 kB]\n",
            "Get:188 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-read-package-json all 4.1.1-1 [10.4 kB]\n",
            "Get:189 http://archive.ubuntu.com/ubuntu jammy/universe amd64 node-tap all 12.0.1+ds-4 [43.6 kB]\n",
            "Get:190 http://archive.ubuntu.com/ubuntu jammy/universe amd64 npm all 8.5.1~ds-1 [894 kB]\n",
            "Fetched 18.8 MB in 6s (3,383 kB/s)\n",
            "Extracting templates from packages: 100%\n",
            "Selecting previously unselected package gyp.\n",
            "(Reading database ... 124505 files and directories currently installed.)\n",
            "Preparing to unpack .../000-gyp_0.1+20210831gitd6c5dd5-5_all.deb ...\n",
            "Unpacking gyp (0.1+20210831gitd6c5dd5-5) ...\n",
            "Selecting previously unselected package javascript-common.\n",
            "Preparing to unpack .../001-javascript-common_11+nmu1_all.deb ...\n",
            "Unpacking javascript-common (11+nmu1) ...\n",
            "Selecting previously unselected package libjs-events.\n",
            "Preparing to unpack .../002-libjs-events_3.3.0+~3.0.0-2_all.deb ...\n",
            "Unpacking libjs-events (3.3.0+~3.0.0-2) ...\n",
            "Selecting previously unselected package libjs-highlight.js.\n",
            "Preparing to unpack .../003-libjs-highlight.js_9.18.5+dfsg1-1_all.deb ...\n",
            "Unpacking libjs-highlight.js (9.18.5+dfsg1-1) ...\n",
            "Selecting previously unselected package libjs-is-typedarray.\n",
            "Preparing to unpack .../004-libjs-is-typedarray_1.0.0-4_all.deb ...\n",
            "Unpacking libjs-is-typedarray (1.0.0-4) ...\n",
            "Selecting previously unselected package libjs-psl.\n",
            "Preparing to unpack .../005-libjs-psl_1.8.0+ds-6_all.deb ...\n",
            "Unpacking libjs-psl (1.8.0+ds-6) ...\n",
            "Selecting previously unselected package libjs-sprintf-js.\n",
            "Preparing to unpack .../006-libjs-sprintf-js_1.1.2+ds1+~1.1.2-1_all.deb ...\n",
            "Unpacking libjs-sprintf-js (1.1.2+ds1+~1.1.2-1) ...\n",
            "Selecting previously unselected package libjs-typedarray-to-buffer.\n",
            "Preparing to unpack .../007-libjs-typedarray-to-buffer_4.0.0-2_all.deb ...\n",
            "Unpacking libjs-typedarray-to-buffer (4.0.0-2) ...\n",
            "Selecting previously unselected package libuv1-dev:amd64.\n",
            "Preparing to unpack .../008-libuv1-dev_1.43.0-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking libuv1-dev:amd64 (1.43.0-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libc-ares2:amd64.\n",
            "Preparing to unpack .../009-libc-ares2_1.18.1-1ubuntu0.22.04.3_amd64.deb ...\n",
            "Unpacking libc-ares2:amd64 (1.18.1-1ubuntu0.22.04.3) ...\n",
            "Selecting previously unselected package libnode72:amd64.\n",
            "Preparing to unpack .../010-libnode72_12.22.9~dfsg-1ubuntu3.6_amd64.deb ...\n",
            "Unpacking libnode72:amd64 (12.22.9~dfsg-1ubuntu3.6) ...\n",
            "Selecting previously unselected package libnode-dev.\n",
            "Preparing to unpack .../011-libnode-dev_12.22.9~dfsg-1ubuntu3.6_amd64.deb ...\n",
            "Unpacking libnode-dev (12.22.9~dfsg-1ubuntu3.6) ...\n",
            "Selecting previously unselected package libnotify4:amd64.\n",
            "Preparing to unpack .../012-libnotify4_0.7.9-3ubuntu5.22.04.1_amd64.deb ...\n",
            "Unpacking libnotify4:amd64 (0.7.9-3ubuntu5.22.04.1) ...\n",
            "Selecting previously unselected package libnotify-bin.\n",
            "Preparing to unpack .../013-libnotify-bin_0.7.9-3ubuntu5.22.04.1_amd64.deb ...\n",
            "Unpacking libnotify-bin (0.7.9-3ubuntu5.22.04.1) ...\n",
            "Selecting previously unselected package nodejs.\n",
            "Preparing to unpack .../014-nodejs_12.22.9~dfsg-1ubuntu3.6_amd64.deb ...\n",
            "Unpacking nodejs (12.22.9~dfsg-1ubuntu3.6) ...\n",
            "Selecting previously unselected package node-abab.\n",
            "Preparing to unpack .../015-node-abab_2.0.5-2_all.deb ...\n",
            "Unpacking node-abab (2.0.5-2) ...\n",
            "Selecting previously unselected package node-ms.\n",
            "Preparing to unpack .../016-node-ms_2.1.3+~cs0.7.31-2_all.deb ...\n",
            "Unpacking node-ms (2.1.3+~cs0.7.31-2) ...\n",
            "Selecting previously unselected package node-debug.\n",
            "Preparing to unpack .../017-node-debug_4.3.2+~cs4.1.7-1_all.deb ...\n",
            "Unpacking node-debug (4.3.2+~cs4.1.7-1) ...\n",
            "Selecting previously unselected package node-yallist.\n",
            "Preparing to unpack .../018-node-yallist_4.0.0+~4.0.1-1_all.deb ...\n",
            "Unpacking node-yallist (4.0.0+~4.0.1-1) ...\n",
            "Selecting previously unselected package node-lru-cache.\n",
            "Preparing to unpack .../019-node-lru-cache_6.0.0+~5.1.1-1_all.deb ...\n",
            "Unpacking node-lru-cache (6.0.0+~5.1.1-1) ...\n",
            "Selecting previously unselected package node-semver.\n",
            "Preparing to unpack .../020-node-semver_7.3.5+~7.3.8-1_all.deb ...\n",
            "Unpacking node-semver (7.3.5+~7.3.8-1) ...\n",
            "Selecting previously unselected package node-agent-base.\n",
            "Preparing to unpack .../021-node-agent-base_6.0.2+~cs5.4.2-1_all.deb ...\n",
            "Unpacking node-agent-base (6.0.2+~cs5.4.2-1) ...\n",
            "Selecting previously unselected package node-ansi-regex.\n",
            "Preparing to unpack .../022-node-ansi-regex_5.0.1-1_all.deb ...\n",
            "Unpacking node-ansi-regex (5.0.1-1) ...\n",
            "Selecting previously unselected package node-ansistyles.\n",
            "Preparing to unpack .../023-node-ansistyles_0.1.3-5_all.deb ...\n",
            "Unpacking node-ansistyles (0.1.3-5) ...\n",
            "Selecting previously unselected package node-aproba.\n",
            "Preparing to unpack .../024-node-aproba_2.0.0-2_all.deb ...\n",
            "Unpacking node-aproba (2.0.0-2) ...\n",
            "Selecting previously unselected package node-delegates.\n",
            "Preparing to unpack .../025-node-delegates_1.0.0-3_all.deb ...\n",
            "Unpacking node-delegates (1.0.0-3) ...\n",
            "Selecting previously unselected package libjs-inherits.\n",
            "Preparing to unpack .../026-libjs-inherits_2.0.4-4_all.deb ...\n",
            "Unpacking libjs-inherits (2.0.4-4) ...\n",
            "Selecting previously unselected package node-inherits.\n",
            "Preparing to unpack .../027-node-inherits_2.0.4-4_all.deb ...\n",
            "Unpacking node-inherits (2.0.4-4) ...\n",
            "Selecting previously unselected package node-core-util-is.\n",
            "Preparing to unpack .../028-node-core-util-is_1.0.3-1_all.deb ...\n",
            "Unpacking node-core-util-is (1.0.3-1) ...\n",
            "Selecting previously unselected package node-safe-buffer.\n",
            "Preparing to unpack .../029-node-safe-buffer_5.2.1+~cs2.1.2-2_all.deb ...\n",
            "Unpacking node-safe-buffer (5.2.1+~cs2.1.2-2) ...\n",
            "Selecting previously unselected package node-string-decoder.\n",
            "Preparing to unpack .../030-node-string-decoder_1.3.0-5_all.deb ...\n",
            "Unpacking node-string-decoder (1.3.0-5) ...\n",
            "Selecting previously unselected package node-process-nextick-args.\n",
            "Preparing to unpack .../031-node-process-nextick-args_2.0.1-2_all.deb ...\n",
            "Unpacking node-process-nextick-args (2.0.1-2) ...\n",
            "Selecting previously unselected package node-util-deprecate.\n",
            "Preparing to unpack .../032-node-util-deprecate_1.0.2-3_all.deb ...\n",
            "Unpacking node-util-deprecate (1.0.2-3) ...\n",
            "Selecting previously unselected package node-isarray.\n",
            "Preparing to unpack .../033-node-isarray_2.0.5-3_all.deb ...\n",
            "Unpacking node-isarray (2.0.5-3) ...\n",
            "Selecting previously unselected package node-readable-stream.\n",
            "Preparing to unpack .../034-node-readable-stream_3.6.0+~cs3.0.0-1_all.deb ...\n",
            "Unpacking node-readable-stream (3.6.0+~cs3.0.0-1) ...\n",
            "Selecting previously unselected package node-are-we-there-yet.\n",
            "Preparing to unpack .../035-node-are-we-there-yet_3.0.0+~1.1.0-1_all.deb ...\n",
            "Unpacking node-are-we-there-yet (3.0.0+~1.1.0-1) ...\n",
            "Selecting previously unselected package node-arrify.\n",
            "Preparing to unpack .../036-node-arrify_2.0.1-2_all.deb ...\n",
            "Unpacking node-arrify (2.0.1-2) ...\n",
            "Selecting previously unselected package node-asap.\n",
            "Preparing to unpack .../037-node-asap_2.0.6+~2.0.0-1_all.deb ...\n",
            "Unpacking node-asap (2.0.6+~2.0.0-1) ...\n",
            "Selecting previously unselected package node-asynckit.\n",
            "Preparing to unpack .../038-node-asynckit_0.4.0-4_all.deb ...\n",
            "Unpacking node-asynckit (0.4.0-4) ...\n",
            "Selecting previously unselected package node-builtins.\n",
            "Preparing to unpack .../039-node-builtins_4.0.0-1_all.deb ...\n",
            "Unpacking node-builtins (4.0.0-1) ...\n",
            "Selecting previously unselected package node-chownr.\n",
            "Preparing to unpack .../040-node-chownr_2.0.0-1_all.deb ...\n",
            "Unpacking node-chownr (2.0.0-1) ...\n",
            "Selecting previously unselected package node-fs.realpath.\n",
            "Preparing to unpack .../041-node-fs.realpath_1.0.0-2_all.deb ...\n",
            "Unpacking node-fs.realpath (1.0.0-2) ...\n",
            "Selecting previously unselected package node-wrappy.\n",
            "Preparing to unpack .../042-node-wrappy_1.0.2-2_all.deb ...\n",
            "Unpacking node-wrappy (1.0.2-2) ...\n",
            "Selecting previously unselected package node-once.\n",
            "Preparing to unpack .../043-node-once_1.4.0-4_all.deb ...\n",
            "Unpacking node-once (1.4.0-4) ...\n",
            "Selecting previously unselected package node-inflight.\n",
            "Preparing to unpack .../044-node-inflight_1.0.6-2_all.deb ...\n",
            "Unpacking node-inflight (1.0.6-2) ...\n",
            "Selecting previously unselected package node-balanced-match.\n",
            "Preparing to unpack .../045-node-balanced-match_2.0.0-1_all.deb ...\n",
            "Unpacking node-balanced-match (2.0.0-1) ...\n",
            "Selecting previously unselected package node-brace-expansion.\n",
            "Preparing to unpack .../046-node-brace-expansion_2.0.1-1_all.deb ...\n",
            "Unpacking node-brace-expansion (2.0.1-1) ...\n",
            "Selecting previously unselected package node-minimatch.\n",
            "Preparing to unpack .../047-node-minimatch_3.1.1+~3.0.5-1_all.deb ...\n",
            "Unpacking node-minimatch (3.1.1+~3.0.5-1) ...\n",
            "Selecting previously unselected package node-path-is-absolute.\n",
            "Preparing to unpack .../048-node-path-is-absolute_2.0.0-2_all.deb ...\n",
            "Unpacking node-path-is-absolute (2.0.0-2) ...\n",
            "Selecting previously unselected package node-glob.\n",
            "Preparing to unpack .../049-node-glob_7.2.1+~cs7.6.15-1_all.deb ...\n",
            "Unpacking node-glob (7.2.1+~cs7.6.15-1) ...\n",
            "Selecting previously unselected package node-graceful-fs.\n",
            "Preparing to unpack .../050-node-graceful-fs_4.2.4+repack-1_all.deb ...\n",
            "Unpacking node-graceful-fs (4.2.4+repack-1) ...\n",
            "Selecting previously unselected package node-mkdirp.\n",
            "Preparing to unpack .../051-node-mkdirp_1.0.4+~1.0.2-1_all.deb ...\n",
            "Unpacking node-mkdirp (1.0.4+~1.0.2-1) ...\n",
            "Selecting previously unselected package node-iferr.\n",
            "Preparing to unpack .../052-node-iferr_1.0.2+~1.0.2-1_all.deb ...\n",
            "Unpacking node-iferr (1.0.2+~1.0.2-1) ...\n",
            "Selecting previously unselected package node-imurmurhash.\n",
            "Preparing to unpack .../053-node-imurmurhash_0.1.4+dfsg+~0.1.1-1_all.deb ...\n",
            "Unpacking node-imurmurhash (0.1.4+dfsg+~0.1.1-1) ...\n",
            "Selecting previously unselected package node-fs-write-stream-atomic.\n",
            "Preparing to unpack .../054-node-fs-write-stream-atomic_1.0.10-5_all.deb ...\n",
            "Unpacking node-fs-write-stream-atomic (1.0.10-5) ...\n",
            "Selecting previously unselected package node-rimraf.\n",
            "Preparing to unpack .../055-node-rimraf_3.0.2-1_all.deb ...\n",
            "Unpacking node-rimraf (3.0.2-1) ...\n",
            "Selecting previously unselected package node-run-queue.\n",
            "Preparing to unpack .../056-node-run-queue_2.0.0-2_all.deb ...\n",
            "Unpacking node-run-queue (2.0.0-2) ...\n",
            "Selecting previously unselected package node-copy-concurrently.\n",
            "Preparing to unpack .../057-node-copy-concurrently_1.0.5-8_all.deb ...\n",
            "Unpacking node-copy-concurrently (1.0.5-8) ...\n",
            "Selecting previously unselected package node-move-concurrently.\n",
            "Preparing to unpack .../058-node-move-concurrently_1.0.1-4_all.deb ...\n",
            "Unpacking node-move-concurrently (1.0.1-4) ...\n",
            "Selecting previously unselected package node-escape-string-regexp.\n",
            "Preparing to unpack .../059-node-escape-string-regexp_4.0.0-2_all.deb ...\n",
            "Unpacking node-escape-string-regexp (4.0.0-2) ...\n",
            "Selecting previously unselected package node-indent-string.\n",
            "Preparing to unpack .../060-node-indent-string_4.0.0-2_all.deb ...\n",
            "Unpacking node-indent-string (4.0.0-2) ...\n",
            "Selecting previously unselected package node-p-map.\n",
            "Preparing to unpack .../061-node-p-map_4.0.0+~3.1.0+~3.0.1-1_all.deb ...\n",
            "Unpacking node-p-map (4.0.0+~3.1.0+~3.0.1-1) ...\n",
            "Selecting previously unselected package node-promise-inflight.\n",
            "Preparing to unpack .../062-node-promise-inflight_1.0.1+~1.0.0-1_all.deb ...\n",
            "Unpacking node-promise-inflight (1.0.1+~1.0.0-1) ...\n",
            "Selecting previously unselected package node-ssri.\n",
            "Preparing to unpack .../063-node-ssri_8.0.1-2_all.deb ...\n",
            "Unpacking node-ssri (8.0.1-2) ...\n",
            "Selecting previously unselected package node-unique-filename.\n",
            "Preparing to unpack .../064-node-unique-filename_1.1.1+ds-1_all.deb ...\n",
            "Unpacking node-unique-filename (1.1.1+ds-1) ...\n",
            "Selecting previously unselected package node-cacache.\n",
            "Preparing to unpack .../065-node-cacache_15.0.5+~cs13.9.21-3_all.deb ...\n",
            "Unpacking node-cacache (15.0.5+~cs13.9.21-3) ...\n",
            "Selecting previously unselected package node-clean-yaml-object.\n",
            "Preparing to unpack .../066-node-clean-yaml-object_0.1.0-5_all.deb ...\n",
            "Unpacking node-clean-yaml-object (0.1.0-5) ...\n",
            "Selecting previously unselected package node-clone.\n",
            "Preparing to unpack .../067-node-clone_2.1.2-3_all.deb ...\n",
            "Unpacking node-clone (2.1.2-3) ...\n",
            "Selecting previously unselected package node-color-name.\n",
            "Preparing to unpack .../068-node-color-name_1.1.4+~1.1.1-2_all.deb ...\n",
            "Unpacking node-color-name (1.1.4+~1.1.1-2) ...\n",
            "Selecting previously unselected package node-color-convert.\n",
            "Preparing to unpack .../069-node-color-convert_2.0.1-1_all.deb ...\n",
            "Unpacking node-color-convert (2.0.1-1) ...\n",
            "Selecting previously unselected package node-colors.\n",
            "Preparing to unpack .../070-node-colors_1.4.0-3_all.deb ...\n",
            "Unpacking node-colors (1.4.0-3) ...\n",
            "Selecting previously unselected package node-strip-ansi.\n",
            "Preparing to unpack .../071-node-strip-ansi_6.0.1-1_all.deb ...\n",
            "Unpacking node-strip-ansi (6.0.1-1) ...\n",
            "Selecting previously unselected package node-defaults.\n",
            "Preparing to unpack .../072-node-defaults_1.0.3+~1.0.3-1_all.deb ...\n",
            "Unpacking node-defaults (1.0.3+~1.0.3-1) ...\n",
            "Selecting previously unselected package node-wcwidth.js.\n",
            "Preparing to unpack .../073-node-wcwidth.js_1.0.2-1_all.deb ...\n",
            "Unpacking node-wcwidth.js (1.0.2-1) ...\n",
            "Selecting previously unselected package node-columnify.\n",
            "Preparing to unpack .../074-node-columnify_1.5.4+~1.5.1-1_all.deb ...\n",
            "Unpacking node-columnify (1.5.4+~1.5.1-1) ...\n",
            "Selecting previously unselected package node-console-control-strings.\n",
            "Preparing to unpack .../075-node-console-control-strings_1.1.0-2_all.deb ...\n",
            "Unpacking node-console-control-strings (1.1.0-2) ...\n",
            "Selecting previously unselected package node-growl.\n",
            "Preparing to unpack .../076-node-growl_1.10.5-4_all.deb ...\n",
            "Unpacking node-growl (1.10.5-4) ...\n",
            "Selecting previously unselected package node-sprintf-js.\n",
            "Preparing to unpack .../077-node-sprintf-js_1.1.2+ds1+~1.1.2-1_all.deb ...\n",
            "Unpacking node-sprintf-js (1.1.2+ds1+~1.1.2-1) ...\n",
            "Selecting previously unselected package node-argparse.\n",
            "Preparing to unpack .../078-node-argparse_2.0.1-2_all.deb ...\n",
            "Unpacking node-argparse (2.0.1-2) ...\n",
            "Selecting previously unselected package node-esprima.\n",
            "Preparing to unpack .../079-node-esprima_4.0.1+ds+~4.0.3-2_all.deb ...\n",
            "Unpacking node-esprima (4.0.1+ds+~4.0.3-2) ...\n",
            "Selecting previously unselected package node-js-yaml.\n",
            "Preparing to unpack .../080-node-js-yaml_4.1.0+dfsg+~4.0.5-6_all.deb ...\n",
            "Unpacking node-js-yaml (4.1.0+dfsg+~4.0.5-6) ...\n",
            "Selecting previously unselected package node-lcov-parse.\n",
            "Preparing to unpack .../081-node-lcov-parse_1.0.0+20170612git80d039574ed9-5_all.deb ...\n",
            "Unpacking node-lcov-parse (1.0.0+20170612git80d039574ed9-5) ...\n",
            "Selecting previously unselected package node-log-driver.\n",
            "Preparing to unpack .../082-node-log-driver_1.2.7+git+20180219+bba1761737-7_all.deb ...\n",
            "Unpacking node-log-driver (1.2.7+git+20180219+bba1761737-7) ...\n",
            "Selecting previously unselected package node-is-plain-obj.\n",
            "Preparing to unpack .../083-node-is-plain-obj_3.0.0-2_all.deb ...\n",
            "Unpacking node-is-plain-obj (3.0.0-2) ...\n",
            "Selecting previously unselected package node-is-buffer.\n",
            "Preparing to unpack .../084-node-is-buffer_2.0.5-2_all.deb ...\n",
            "Unpacking node-is-buffer (2.0.5-2) ...\n",
            "Selecting previously unselected package node-kind-of.\n",
            "Preparing to unpack .../085-node-kind-of_6.0.3+dfsg-2_all.deb ...\n",
            "Unpacking node-kind-of (6.0.3+dfsg-2) ...\n",
            "Selecting previously unselected package node-minimist.\n",
            "Preparing to unpack .../086-node-minimist_1.2.5+~cs5.3.2-1_all.deb ...\n",
            "Unpacking node-minimist (1.2.5+~cs5.3.2-1) ...\n",
            "Selecting previously unselected package node-cssom.\n",
            "Preparing to unpack .../087-node-cssom_0.4.4-3_all.deb ...\n",
            "Unpacking node-cssom (0.4.4-3) ...\n",
            "Selecting previously unselected package node-cssstyle.\n",
            "Preparing to unpack .../088-node-cssstyle_2.3.0-2_all.deb ...\n",
            "Unpacking node-cssstyle (2.3.0-2) ...\n",
            "Selecting previously unselected package node-delayed-stream.\n",
            "Preparing to unpack .../089-node-delayed-stream_1.0.0-5_all.deb ...\n",
            "Unpacking node-delayed-stream (1.0.0-5) ...\n",
            "Selecting previously unselected package node-combined-stream.\n",
            "Preparing to unpack .../090-node-combined-stream_1.0.8+~1.0.3-1_all.deb ...\n",
            "Unpacking node-combined-stream (1.0.8+~1.0.3-1) ...\n",
            "Selecting previously unselected package node-mime.\n",
            "Preparing to unpack .../091-node-mime_3.0.0+dfsg+~cs3.96.1-1_all.deb ...\n",
            "Unpacking node-mime (3.0.0+dfsg+~cs3.96.1-1) ...\n",
            "Selecting previously unselected package node-mime-types.\n",
            "Preparing to unpack .../092-node-mime-types_2.1.33-1_all.deb ...\n",
            "Unpacking node-mime-types (2.1.33-1) ...\n",
            "Selecting previously unselected package node-form-data.\n",
            "Preparing to unpack .../093-node-form-data_3.0.1-1_all.deb ...\n",
            "Unpacking node-form-data (3.0.1-1) ...\n",
            "Selecting previously unselected package node-events.\n",
            "Preparing to unpack .../094-node-events_3.3.0+~3.0.0-2_all.deb ...\n",
            "Unpacking node-events (3.3.0+~3.0.0-2) ...\n",
            "Selecting previously unselected package node-https-proxy-agent.\n",
            "Preparing to unpack .../095-node-https-proxy-agent_5.0.0+~cs8.0.0-3_all.deb ...\n",
            "Unpacking node-https-proxy-agent (5.0.0+~cs8.0.0-3) ...\n",
            "Selecting previously unselected package node-iconv-lite.\n",
            "Preparing to unpack .../096-node-iconv-lite_0.6.3-2_all.deb ...\n",
            "Unpacking node-iconv-lite (0.6.3-2) ...\n",
            "Selecting previously unselected package node-lodash-packages.\n",
            "Preparing to unpack .../097-node-lodash-packages_4.17.21+dfsg+~cs8.31.198.20210220-5_all.deb ...\n",
            "Unpacking node-lodash-packages (4.17.21+dfsg+~cs8.31.198.20210220-5) ...\n",
            "Selecting previously unselected package node-stealthy-require.\n",
            "Preparing to unpack .../098-node-stealthy-require_1.1.1-5_all.deb ...\n",
            "Unpacking node-stealthy-require (1.1.1-5) ...\n",
            "Selecting previously unselected package node-punycode.\n",
            "Preparing to unpack .../099-node-punycode_2.1.1-5_all.deb ...\n",
            "Unpacking node-punycode (2.1.1-5) ...\n",
            "Selecting previously unselected package node-psl.\n",
            "Preparing to unpack .../100-node-psl_1.8.0+ds-6_all.deb ...\n",
            "Unpacking node-psl (1.8.0+ds-6) ...\n",
            "Selecting previously unselected package node-universalify.\n",
            "Preparing to unpack .../101-node-universalify_2.0.0-3_all.deb ...\n",
            "Unpacking node-universalify (2.0.0-3) ...\n",
            "Selecting previously unselected package node-tough-cookie.\n",
            "Preparing to unpack .../102-node-tough-cookie_4.0.0-2_all.deb ...\n",
            "Unpacking node-tough-cookie (4.0.0-2) ...\n",
            "Selecting previously unselected package node-webidl-conversions.\n",
            "Preparing to unpack .../103-node-webidl-conversions_7.0.0~1.1.0+~cs15.1.20180823-2_all.deb ...\n",
            "Unpacking node-webidl-conversions (7.0.0~1.1.0+~cs15.1.20180823-2) ...\n",
            "Selecting previously unselected package node-commander.\n",
            "Preparing to unpack .../104-node-commander_9.0.0-2_all.deb ...\n",
            "Unpacking node-commander (9.0.0-2) ...\n",
            "Selecting previously unselected package node-mute-stream.\n",
            "Preparing to unpack .../105-node-mute-stream_0.0.8+~0.0.1-1_all.deb ...\n",
            "Unpacking node-mute-stream (0.0.8+~0.0.1-1) ...\n",
            "Selecting previously unselected package node-read.\n",
            "Preparing to unpack .../106-node-read_1.0.7-3_all.deb ...\n",
            "Unpacking node-read (1.0.7-3) ...\n",
            "Selecting previously unselected package node-ws.\n",
            "Preparing to unpack .../107-node-ws_8.5.0+~cs13.3.3-2_all.deb ...\n",
            "Unpacking node-ws (8.5.0+~cs13.3.3-2) ...\n",
            "Selecting previously unselected package node-jsdom.\n",
            "Preparing to unpack .../108-node-jsdom_19.0.0+~cs90.11.27-1_all.deb ...\n",
            "Unpacking node-jsdom (19.0.0+~cs90.11.27-1) ...\n",
            "Selecting previously unselected package node-fetch.\n",
            "Preparing to unpack .../109-node-fetch_2.6.7+~2.5.12-1_all.deb ...\n",
            "Unpacking node-fetch (2.6.7+~2.5.12-1) ...\n",
            "Selecting previously unselected package node-coveralls.\n",
            "Preparing to unpack .../110-node-coveralls_3.1.1-1_all.deb ...\n",
            "Unpacking node-coveralls (3.1.1-1) ...\n",
            "Selecting previously unselected package node-mimic-response.\n",
            "Preparing to unpack .../111-node-mimic-response_3.1.0-7_all.deb ...\n",
            "Unpacking node-mimic-response (3.1.0-7) ...\n",
            "Selecting previously unselected package node-decompress-response.\n",
            "Preparing to unpack .../112-node-decompress-response_6.0.0-2_all.deb ...\n",
            "Unpacking node-decompress-response (6.0.0-2) ...\n",
            "Selecting previously unselected package node-diff.\n",
            "Preparing to unpack .../113-node-diff_5.0.0~dfsg+~5.0.1-3_all.deb ...\n",
            "Unpacking node-diff (5.0.0~dfsg+~5.0.1-3) ...\n",
            "Selecting previously unselected package node-err-code.\n",
            "Preparing to unpack .../114-node-err-code_2.0.3+dfsg-3_all.deb ...\n",
            "Unpacking node-err-code (2.0.3+dfsg-3) ...\n",
            "Selecting previously unselected package node-time-stamp.\n",
            "Preparing to unpack .../115-node-time-stamp_2.2.0-1_all.deb ...\n",
            "Unpacking node-time-stamp (2.2.0-1) ...\n",
            "Selecting previously unselected package node-fancy-log.\n",
            "Preparing to unpack .../116-node-fancy-log_1.3.3+~cs1.3.1-2_all.deb ...\n",
            "Unpacking node-fancy-log (1.3.3+~cs1.3.1-2) ...\n",
            "Selecting previously unselected package node-signal-exit.\n",
            "Preparing to unpack .../117-node-signal-exit_3.0.6+~3.0.1-1_all.deb ...\n",
            "Unpacking node-signal-exit (3.0.6+~3.0.1-1) ...\n",
            "Selecting previously unselected package node-foreground-child.\n",
            "Preparing to unpack .../118-node-foreground-child_2.0.0-3_all.deb ...\n",
            "Unpacking node-foreground-child (2.0.0-3) ...\n",
            "Selecting previously unselected package node-function-bind.\n",
            "Preparing to unpack .../119-node-function-bind_1.1.1+repacked+~1.0.3-1_all.deb ...\n",
            "Unpacking node-function-bind (1.1.1+repacked+~1.0.3-1) ...\n",
            "Selecting previously unselected package node-has-unicode.\n",
            "Preparing to unpack .../120-node-has-unicode_2.0.1-4_all.deb ...\n",
            "Unpacking node-has-unicode (2.0.1-4) ...\n",
            "Selecting previously unselected package node-ansi-styles.\n",
            "Preparing to unpack .../121-node-ansi-styles_4.3.0+~4.2.0-1_all.deb ...\n",
            "Unpacking node-ansi-styles (4.3.0+~4.2.0-1) ...\n",
            "Selecting previously unselected package node-slice-ansi.\n",
            "Preparing to unpack .../122-node-slice-ansi_5.0.0+~cs9.0.0-4_all.deb ...\n",
            "Unpacking node-slice-ansi (5.0.0+~cs9.0.0-4) ...\n",
            "Selecting previously unselected package node-string-width.\n",
            "Preparing to unpack .../123-node-string-width_4.2.3+~cs13.2.3-1_all.deb ...\n",
            "Unpacking node-string-width (4.2.3+~cs13.2.3-1) ...\n",
            "Selecting previously unselected package node-wide-align.\n",
            "Preparing to unpack .../124-node-wide-align_1.1.3-4_all.deb ...\n",
            "Unpacking node-wide-align (1.1.3-4) ...\n",
            "Selecting previously unselected package node-gauge.\n",
            "Preparing to unpack .../125-node-gauge_4.0.2-1_all.deb ...\n",
            "Unpacking node-gauge (4.0.2-1) ...\n",
            "Selecting previously unselected package node-end-of-stream.\n",
            "Preparing to unpack .../126-node-end-of-stream_1.4.4+~1.4.1-1_all.deb ...\n",
            "Unpacking node-end-of-stream (1.4.4+~1.4.1-1) ...\n",
            "Selecting previously unselected package node-pump.\n",
            "Preparing to unpack .../127-node-pump_3.0.0-5_all.deb ...\n",
            "Unpacking node-pump (3.0.0-5) ...\n",
            "Selecting previously unselected package node-get-stream.\n",
            "Preparing to unpack .../128-node-get-stream_6.0.1-1_all.deb ...\n",
            "Unpacking node-get-stream (6.0.1-1) ...\n",
            "Selecting previously unselected package node-lowercase-keys.\n",
            "Preparing to unpack .../129-node-lowercase-keys_2.0.0-2_all.deb ...\n",
            "Unpacking node-lowercase-keys (2.0.0-2) ...\n",
            "Selecting previously unselected package node-json-buffer.\n",
            "Preparing to unpack .../130-node-json-buffer_3.0.1-1_all.deb ...\n",
            "Unpacking node-json-buffer (3.0.1-1) ...\n",
            "Selecting previously unselected package node-p-cancelable.\n",
            "Preparing to unpack .../131-node-p-cancelable_2.1.1-1_all.deb ...\n",
            "Unpacking node-p-cancelable (2.1.1-1) ...\n",
            "Selecting previously unselected package node-quick-lru.\n",
            "Preparing to unpack .../132-node-quick-lru_5.1.1-1_all.deb ...\n",
            "Unpacking node-quick-lru (5.1.1-1) ...\n",
            "Selecting previously unselected package node-got.\n",
            "Preparing to unpack .../133-node-got_11.8.3+~cs58.7.37-1_all.deb ...\n",
            "Unpacking node-got (11.8.3+~cs58.7.37-1) ...\n",
            "Selecting previously unselected package node-has-flag.\n",
            "Preparing to unpack .../134-node-has-flag_4.0.0-2_all.deb ...\n",
            "Unpacking node-has-flag (4.0.0-2) ...\n",
            "Selecting previously unselected package node-hosted-git-info.\n",
            "Preparing to unpack .../135-node-hosted-git-info_4.0.2-1_all.deb ...\n",
            "Unpacking node-hosted-git-info (4.0.2-1) ...\n",
            "Selecting previously unselected package node-ip.\n",
            "Preparing to unpack .../136-node-ip_1.1.5+~1.1.0-1_all.deb ...\n",
            "Unpacking node-ip (1.1.5+~1.1.0-1) ...\n",
            "Selecting previously unselected package node-ip-regex.\n",
            "Preparing to unpack .../137-node-ip-regex_4.3.0+~4.1.1-1_all.deb ...\n",
            "Unpacking node-ip-regex (4.3.0+~4.1.1-1) ...\n",
            "Selecting previously unselected package node-is-typedarray.\n",
            "Preparing to unpack .../138-node-is-typedarray_1.0.0-4_all.deb ...\n",
            "Unpacking node-is-typedarray (1.0.0-4) ...\n",
            "Selecting previously unselected package node-isexe.\n",
            "Preparing to unpack .../139-node-isexe_2.0.0+~2.0.1-4_all.deb ...\n",
            "Unpacking node-isexe (2.0.0+~2.0.1-4) ...\n",
            "Selecting previously unselected package node-json-parse-better-errors.\n",
            "Preparing to unpack .../140-node-json-parse-better-errors_1.0.2+~cs3.3.1-1_all.deb ...\n",
            "Unpacking node-json-parse-better-errors (1.0.2+~cs3.3.1-1) ...\n",
            "Selecting previously unselected package node-encoding.\n",
            "Preparing to unpack .../141-node-encoding_0.1.13-2_all.deb ...\n",
            "Unpacking node-encoding (0.1.13-2) ...\n",
            "Selecting previously unselected package node-jsonparse.\n",
            "Preparing to unpack .../142-node-jsonparse_1.3.1-10_all.deb ...\n",
            "Unpacking node-jsonparse (1.3.1-10) ...\n",
            "Selecting previously unselected package node-minipass.\n",
            "Preparing to unpack .../143-node-minipass_3.1.6+~cs8.7.18-1_all.deb ...\n",
            "Unpacking node-minipass (3.1.6+~cs8.7.18-1) ...\n",
            "Selecting previously unselected package node-npm-bundled.\n",
            "Preparing to unpack .../144-node-npm-bundled_1.1.2-1_all.deb ...\n",
            "Unpacking node-npm-bundled (1.1.2-1) ...\n",
            "Selecting previously unselected package node-osenv.\n",
            "Preparing to unpack .../145-node-osenv_0.1.5+~0.1.0-1_all.deb ...\n",
            "Unpacking node-osenv (0.1.5+~0.1.0-1) ...\n",
            "Selecting previously unselected package node-validate-npm-package-name.\n",
            "Preparing to unpack .../146-node-validate-npm-package-name_3.0.0-4_all.deb ...\n",
            "Unpacking node-validate-npm-package-name (3.0.0-4) ...\n",
            "Selecting previously unselected package node-npm-package-arg.\n",
            "Preparing to unpack .../147-node-npm-package-arg_8.1.5-1_all.deb ...\n",
            "Unpacking node-npm-package-arg (8.1.5-1) ...\n",
            "Selecting previously unselected package node-object-assign.\n",
            "Preparing to unpack .../148-node-object-assign_4.1.1-6_all.deb ...\n",
            "Unpacking node-object-assign (4.1.1-6) ...\n",
            "Selecting previously unselected package node-opener.\n",
            "Preparing to unpack .../149-node-opener_1.5.2+~1.4.0-1_all.deb ...\n",
            "Unpacking node-opener (1.5.2+~1.4.0-1) ...\n",
            "Selecting previously unselected package node-retry.\n",
            "Preparing to unpack .../150-node-retry_0.13.1+~0.12.1-1_all.deb ...\n",
            "Unpacking node-retry (0.13.1+~0.12.1-1) ...\n",
            "Selecting previously unselected package node-promise-retry.\n",
            "Preparing to unpack .../151-node-promise-retry_2.0.1-2_all.deb ...\n",
            "Unpacking node-promise-retry (2.0.1-2) ...\n",
            "Selecting previously unselected package node-promzard.\n",
            "Preparing to unpack .../152-node-promzard_0.3.0-2_all.deb ...\n",
            "Unpacking node-promzard (0.3.0-2) ...\n",
            "Selecting previously unselected package node-set-blocking.\n",
            "Preparing to unpack .../153-node-set-blocking_2.0.0-2_all.deb ...\n",
            "Unpacking node-set-blocking (2.0.0-2) ...\n",
            "Selecting previously unselected package node-slash.\n",
            "Preparing to unpack .../154-node-slash_3.0.0-2_all.deb ...\n",
            "Unpacking node-slash (3.0.0-2) ...\n",
            "Selecting previously unselected package libjs-source-map.\n",
            "Preparing to unpack .../155-libjs-source-map_0.7.0++dfsg2+really.0.6.1-9_all.deb ...\n",
            "Unpacking libjs-source-map (0.7.0++dfsg2+really.0.6.1-9) ...\n",
            "Selecting previously unselected package node-source-map.\n",
            "Preparing to unpack .../156-node-source-map_0.7.0++dfsg2+really.0.6.1-9_all.deb ...\n",
            "Unpacking node-source-map (0.7.0++dfsg2+really.0.6.1-9) ...\n",
            "Selecting previously unselected package node-source-map-support.\n",
            "Preparing to unpack .../157-node-source-map-support_0.5.21+ds+~0.5.4-1_all.deb ...\n",
            "Unpacking node-source-map-support (0.5.21+ds+~0.5.4-1) ...\n",
            "Selecting previously unselected package node-spdx-license-ids.\n",
            "Preparing to unpack .../158-node-spdx-license-ids_3.0.11-1_all.deb ...\n",
            "Unpacking node-spdx-license-ids (3.0.11-1) ...\n",
            "Selecting previously unselected package node-spdx-exceptions.\n",
            "Preparing to unpack .../159-node-spdx-exceptions_2.3.0-2_all.deb ...\n",
            "Unpacking node-spdx-exceptions (2.3.0-2) ...\n",
            "Selecting previously unselected package node-spdx-expression-parse.\n",
            "Preparing to unpack .../160-node-spdx-expression-parse_3.0.1+~3.0.1-1_all.deb ...\n",
            "Unpacking node-spdx-expression-parse (3.0.1+~3.0.1-1) ...\n",
            "Selecting previously unselected package node-spdx-correct.\n",
            "Preparing to unpack .../161-node-spdx-correct_3.1.1-2_all.deb ...\n",
            "Unpacking node-spdx-correct (3.1.1-2) ...\n",
            "Selecting previously unselected package node-stack-utils.\n",
            "Preparing to unpack .../162-node-stack-utils_2.0.5+~2.0.1-1_all.deb ...\n",
            "Unpacking node-stack-utils (2.0.5+~2.0.1-1) ...\n",
            "Selecting previously unselected package node-supports-color.\n",
            "Preparing to unpack .../163-node-supports-color_8.1.1+~8.1.1-1_all.deb ...\n",
            "Unpacking node-supports-color (8.1.1+~8.1.1-1) ...\n",
            "Selecting previously unselected package node-tap-parser.\n",
            "Preparing to unpack .../164-node-tap-parser_7.0.0+ds1-6_all.deb ...\n",
            "Unpacking node-tap-parser (7.0.0+ds1-6) ...\n",
            "Selecting previously unselected package node-tap-mocha-reporter.\n",
            "Preparing to unpack .../165-node-tap-mocha-reporter_3.0.7+ds-2_all.deb ...\n",
            "Unpacking node-tap-mocha-reporter (3.0.7+ds-2) ...\n",
            "Selecting previously unselected package node-text-table.\n",
            "Preparing to unpack .../166-node-text-table_0.2.0-4_all.deb ...\n",
            "Unpacking node-text-table (0.2.0-4) ...\n",
            "Selecting previously unselected package node-tmatch.\n",
            "Preparing to unpack .../167-node-tmatch_5.0.0-4_all.deb ...\n",
            "Unpacking node-tmatch (5.0.0-4) ...\n",
            "Selecting previously unselected package node-typedarray-to-buffer.\n",
            "Preparing to unpack .../168-node-typedarray-to-buffer_4.0.0-2_all.deb ...\n",
            "Unpacking node-typedarray-to-buffer (4.0.0-2) ...\n",
            "Selecting previously unselected package node-validate-npm-package-license.\n",
            "Preparing to unpack .../169-node-validate-npm-package-license_3.0.4-2_all.deb ...\n",
            "Unpacking node-validate-npm-package-license (3.0.4-2) ...\n",
            "Selecting previously unselected package node-whatwg-fetch.\n",
            "Preparing to unpack .../170-node-whatwg-fetch_3.6.2-5_all.deb ...\n",
            "Unpacking node-whatwg-fetch (3.6.2-5) ...\n",
            "Selecting previously unselected package node-write-file-atomic.\n",
            "Preparing to unpack .../171-node-write-file-atomic_3.0.3+~3.0.2-1_all.deb ...\n",
            "Unpacking node-write-file-atomic (3.0.3+~3.0.2-1) ...\n",
            "Selecting previously unselected package nodejs-doc.\n",
            "Preparing to unpack .../172-nodejs-doc_12.22.9~dfsg-1ubuntu3.6_all.deb ...\n",
            "Unpacking nodejs-doc (12.22.9~dfsg-1ubuntu3.6) ...\n",
            "Selecting previously unselected package node-abbrev.\n",
            "Preparing to unpack .../173-node-abbrev_1.1.1+~1.1.2-1_all.deb ...\n",
            "Unpacking node-abbrev (1.1.1+~1.1.2-1) ...\n",
            "Selecting previously unselected package node-archy.\n",
            "Preparing to unpack .../174-node-archy_1.0.0-4_all.deb ...\n",
            "Unpacking node-archy (1.0.0-4) ...\n",
            "Selecting previously unselected package node-chalk.\n",
            "Preparing to unpack .../175-node-chalk_4.1.2-1_all.deb ...\n",
            "Unpacking node-chalk (4.1.2-1) ...\n",
            "Selecting previously unselected package node-cli-table.\n",
            "Preparing to unpack .../176-node-cli-table_0.3.11+~cs0.13.3-1_all.deb ...\n",
            "Unpacking node-cli-table (0.3.11+~cs0.13.3-1) ...\n",
            "Selecting previously unselected package node-depd.\n",
            "Preparing to unpack .../177-node-depd_2.0.0-2_all.deb ...\n",
            "Unpacking node-depd (2.0.0-2) ...\n",
            "Selecting previously unselected package node-nopt.\n",
            "Preparing to unpack .../178-node-nopt_5.0.0-2_all.deb ...\n",
            "Unpacking node-nopt (5.0.0-2) ...\n",
            "Selecting previously unselected package node-npmlog.\n",
            "Preparing to unpack .../179-node-npmlog_6.0.1+~4.1.4-1_all.deb ...\n",
            "Unpacking node-npmlog (6.0.1+~4.1.4-1) ...\n",
            "Selecting previously unselected package node-tar.\n",
            "Preparing to unpack .../180-node-tar_6.1.11+ds1+~cs6.0.6-1_all.deb ...\n",
            "Unpacking node-tar (6.1.11+ds1+~cs6.0.6-1) ...\n",
            "Selecting previously unselected package node-which.\n",
            "Preparing to unpack .../181-node-which_2.0.2+~cs1.3.2-2_all.deb ...\n",
            "Unpacking node-which (2.0.2+~cs1.3.2-2) ...\n",
            "Selecting previously unselected package node-gyp.\n",
            "Preparing to unpack .../182-node-gyp_8.4.1-1_all.deb ...\n",
            "Unpacking node-gyp (8.4.1-1) ...\n",
            "Selecting previously unselected package node-ini.\n",
            "Preparing to unpack .../183-node-ini_2.0.1-1_all.deb ...\n",
            "Unpacking node-ini (2.0.1-1) ...\n",
            "Selecting previously unselected package node-negotiator.\n",
            "Preparing to unpack .../184-node-negotiator_0.6.2+~0.6.1-1_all.deb ...\n",
            "Unpacking node-negotiator (0.6.2+~0.6.1-1) ...\n",
            "Selecting previously unselected package node-resolve.\n",
            "Preparing to unpack .../185-node-resolve_1.20.0+~cs5.27.9-1_all.deb ...\n",
            "Unpacking node-resolve (1.20.0+~cs5.27.9-1) ...\n",
            "Selecting previously unselected package node-normalize-package-data.\n",
            "Preparing to unpack .../186-node-normalize-package-data_3.0.3+~2.4.1-1_all.deb ...\n",
            "Unpacking node-normalize-package-data (3.0.3+~2.4.1-1) ...\n",
            "Selecting previously unselected package node-read-package-json.\n",
            "Preparing to unpack .../187-node-read-package-json_4.1.1-1_all.deb ...\n",
            "Unpacking node-read-package-json (4.1.1-1) ...\n",
            "Selecting previously unselected package node-tap.\n",
            "Preparing to unpack .../188-node-tap_12.0.1+ds-4_all.deb ...\n",
            "Unpacking node-tap (12.0.1+ds-4) ...\n",
            "Selecting previously unselected package npm.\n",
            "Preparing to unpack .../189-npm_8.5.1~ds-1_all.deb ...\n",
            "Unpacking npm (8.5.1~ds-1) ...\n",
            "Setting up node-delayed-stream (1.0.0-5) ...\n",
            "Setting up javascript-common (11+nmu1) ...\n",
            "apache2_invoke: Enable configuration javascript-common\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of reload.\n",
            "Setting up libuv1-dev:amd64 (1.43.0-1ubuntu0.1) ...\n",
            "Setting up node-fs.realpath (1.0.0-2) ...\n",
            "Setting up node-diff (5.0.0~dfsg+~5.0.1-3) ...\n",
            "Setting up node-abbrev (1.1.1+~1.1.2-1) ...\n",
            "Setting up libjs-sprintf-js (1.1.2+ds1+~1.1.2-1) ...\n",
            "Setting up node-yallist (4.0.0+~4.0.1-1) ...\n",
            "Setting up libjs-inherits (2.0.4-4) ...\n",
            "Setting up node-p-cancelable (2.1.1-1) ...\n",
            "Setting up node-ansi-regex (5.0.1-1) ...\n",
            "Setting up node-slash (3.0.0-2) ...\n",
            "Setting up node-util-deprecate (1.0.2-3) ...\n",
            "Setting up node-retry (0.13.1+~0.12.1-1) ...\n",
            "Setting up node-arrify (2.0.1-2) ...\n",
            "Setting up node-ansistyles (0.1.3-5) ...\n",
            "Setting up node-delegates (1.0.0-3) ...\n",
            "Setting up node-depd (2.0.0-2) ...\n",
            "Setting up node-isexe (2.0.0+~2.0.1-4) ...\n",
            "Setting up node-jsonparse (1.3.1-10) ...\n",
            "Setting up node-escape-string-regexp (4.0.0-2) ...\n",
            "Setting up libjs-source-map (0.7.0++dfsg2+really.0.6.1-9) ...\n",
            "Setting up node-negotiator (0.6.2+~0.6.1-1) ...\n",
            "Setting up node-color-name (1.1.4+~1.1.1-2) ...\n",
            "Setting up libc-ares2:amd64 (1.18.1-1ubuntu0.22.04.3) ...\n",
            "Setting up node-indent-string (4.0.0-2) ...\n",
            "Setting up libnode72:amd64 (12.22.9~dfsg-1ubuntu3.6) ...\n",
            "Setting up node-function-bind (1.1.1+repacked+~1.0.3-1) ...\n",
            "Setting up node-p-map (4.0.0+~3.1.0+~3.0.1-1) ...\n",
            "Setting up node-iferr (1.0.2+~1.0.2-1) ...\n",
            "Setting up node-chownr (2.0.0-1) ...\n",
            "Setting up node-has-flag (4.0.0-2) ...\n",
            "Setting up node-lodash-packages (4.17.21+dfsg+~cs8.31.198.20210220-5) ...\n",
            "Setting up libjs-psl (1.8.0+ds-6) ...\n",
            "Setting up node-asap (2.0.6+~2.0.0-1) ...\n",
            "Setting up node-inherits (2.0.4-4) ...\n",
            "Setting up node-path-is-absolute (2.0.0-2) ...\n",
            "Setting up node-universalify (2.0.0-3) ...\n",
            "Setting up node-ini (2.0.1-1) ...\n",
            "Setting up node-safe-buffer (5.2.1+~cs2.1.2-2) ...\n",
            "Setting up node-promise-inflight (1.0.1+~1.0.0-1) ...\n",
            "Setting up node-json-parse-better-errors (1.0.2+~cs3.3.1-1) ...\n",
            "Setting up node-sprintf-js (1.1.2+ds1+~1.1.2-1) ...\n",
            "Setting up node-tmatch (5.0.0-4) ...\n",
            "Setting up node-err-code (2.0.3+dfsg-3) ...\n",
            "Setting up node-balanced-match (2.0.0-1) ...\n",
            "Setting up node-brace-expansion (2.0.1-1) ...\n",
            "Setting up libnotify4:amd64 (0.7.9-3ubuntu5.22.04.1) ...\n",
            "Setting up node-spdx-exceptions (2.3.0-2) ...\n",
            "Setting up node-set-blocking (2.0.0-2) ...\n",
            "Setting up node-npm-bundled (1.1.2-1) ...\n",
            "Setting up node-signal-exit (3.0.6+~3.0.1-1) ...\n",
            "Setting up node-source-map (0.7.0++dfsg2+really.0.6.1-9) ...\n",
            "Setting up node-wrappy (1.0.2-2) ...\n",
            "Setting up node-text-table (0.2.0-4) ...\n",
            "Setting up node-asynckit (0.4.0-4) ...\n",
            "Setting up node-ip (1.1.5+~1.1.0-1) ...\n",
            "Setting up node-quick-lru (5.1.1-1) ...\n",
            "Setting up libnotify-bin (0.7.9-3ubuntu5.22.04.1) ...\n",
            "Setting up node-mute-stream (0.0.8+~0.0.1-1) ...\n",
            "Setting up node-mimic-response (3.1.0-7) ...\n",
            "Setting up node-commander (9.0.0-2) ...\n",
            "Setting up node-whatwg-fetch (3.6.2-5) ...\n",
            "Setting up libjs-typedarray-to-buffer (4.0.0-2) ...\n",
            "Setting up libjs-highlight.js (9.18.5+dfsg1-1) ...\n",
            "Setting up node-clean-yaml-object (0.1.0-5) ...\n",
            "Setting up node-ip-regex (4.3.0+~4.1.1-1) ...\n",
            "Setting up node-stealthy-require (1.1.1-5) ...\n",
            "Setting up node-spdx-license-ids (3.0.11-1) ...\n",
            "Setting up node-string-decoder (1.3.0-5) ...\n",
            "Setting up node-time-stamp (2.2.0-1) ...\n",
            "Setting up libjs-events (3.3.0+~3.0.0-2) ...\n",
            "Setting up node-core-util-is (1.0.3-1) ...\n",
            "Setting up node-minimatch (3.1.1+~3.0.5-1) ...\n",
            "Setting up node-imurmurhash (0.1.4+dfsg+~0.1.1-1) ...\n",
            "Setting up node-foreground-child (2.0.0-3) ...\n",
            "Setting up node-read (1.0.7-3) ...\n",
            "Setting up node-is-buffer (2.0.5-2) ...\n",
            "Setting up node-color-convert (2.0.1-1) ...\n",
            "Setting up node-webidl-conversions (7.0.0~1.1.0+~cs15.1.20180823-2) ...\n",
            "Setting up node-isarray (2.0.5-3) ...\n",
            "Setting up node-osenv (0.1.5+~0.1.0-1) ...\n",
            "Setting up node-is-plain-obj (3.0.0-2) ...\n",
            "Setting up libjs-is-typedarray (1.0.0-4) ...\n",
            "Setting up node-lowercase-keys (2.0.0-2) ...\n",
            "Setting up node-decompress-response (6.0.0-2) ...\n",
            "Setting up node-process-nextick-args (2.0.1-2) ...\n",
            "Setting up node-has-unicode (2.0.1-4) ...\n",
            "Setting up gyp (0.1+20210831gitd6c5dd5-5) ...\n",
            "Setting up node-readable-stream (3.6.0+~cs3.0.0-1) ...\n",
            "Setting up node-lru-cache (6.0.0+~5.1.1-1) ...\n",
            "Setting up node-promise-retry (2.0.1-2) ...\n",
            "Setting up node-supports-color (8.1.1+~8.1.1-1) ...\n",
            "Setting up node-once (1.4.0-4) ...\n",
            "Setting up libnode-dev (12.22.9~dfsg-1ubuntu3.6) ...\n",
            "Setting up node-resolve (1.20.0+~cs5.27.9-1) ...\n",
            "Setting up node-are-we-there-yet (3.0.0+~1.1.0-1) ...\n",
            "Setting up node-kind-of (6.0.3+dfsg-2) ...\n",
            "Setting up node-growl (1.10.5-4) ...\n",
            "Setting up nodejs (12.22.9~dfsg-1ubuntu3.6) ...\n",
            "update-alternatives: using /usr/bin/nodejs to provide /usr/bin/js (js) in auto mode\n",
            "Setting up node-minimist (1.2.5+~cs5.3.2-1) ...\n",
            "Setting up node-abab (2.0.5-2) ...\n",
            "Setting up node-argparse (2.0.1-2) ...\n",
            "Setting up node-fancy-log (1.3.3+~cs1.3.1-2) ...\n",
            "Setting up node-clone (2.1.2-3) ...\n",
            "Setting up node-promzard (0.3.0-2) ...\n",
            "Setting up node-mime (3.0.0+dfsg+~cs3.96.1-1) ...\n",
            "Setting up node-source-map-support (0.5.21+ds+~0.5.4-1) ...\n",
            "Setting up node-iconv-lite (0.6.3-2) ...\n",
            "Setting up node-combined-stream (1.0.8+~1.0.3-1) ...\n",
            "Setting up node-unique-filename (1.1.1+ds-1) ...\n",
            "Setting up node-ansi-styles (4.3.0+~4.2.0-1) ...\n",
            "Setting up node-mime-types (2.1.33-1) ...\n",
            "Setting up node-lcov-parse (1.0.0+20170612git80d039574ed9-5) ...\n",
            "Setting up node-cssom (0.4.4-3) ...\n",
            "Setting up node-form-data (3.0.1-1) ...\n",
            "Setting up node-strip-ansi (6.0.1-1) ...\n",
            "Setting up node-chalk (4.1.2-1) ...\n",
            "Setting up node-spdx-expression-parse (3.0.1+~3.0.1-1) ...\n",
            "Setting up node-which (2.0.2+~cs1.3.2-2) ...\n",
            "Setting up nodejs-doc (12.22.9~dfsg-1ubuntu3.6) ...\n",
            "Setting up node-punycode (2.1.1-5) ...\n",
            "Setting up node-defaults (1.0.3+~1.0.3-1) ...\n",
            "Setting up node-is-typedarray (1.0.0-4) ...\n",
            "Setting up node-graceful-fs (4.2.4+repack-1) ...\n",
            "Setting up node-inflight (1.0.6-2) ...\n",
            "Setting up node-hosted-git-info (4.0.2-1) ...\n",
            "Setting up node-aproba (2.0.0-2) ...\n",
            "Setting up node-esprima (4.0.1+ds+~4.0.3-2) ...\n",
            "Setting up node-mkdirp (1.0.4+~1.0.2-1) ...\n",
            "Setting up node-run-queue (2.0.0-2) ...\n",
            "Setting up node-opener (1.5.2+~1.4.0-1) ...\n",
            "Setting up node-archy (1.0.0-4) ...\n",
            "Setting up node-encoding (0.1.13-2) ...\n",
            "Setting up node-js-yaml (4.1.0+dfsg+~4.0.5-6) ...\n",
            "Setting up node-nopt (5.0.0-2) ...\n",
            "Setting up node-slice-ansi (5.0.0+~cs9.0.0-4) ...\n",
            "Setting up node-ms (2.1.3+~cs0.7.31-2) ...\n",
            "Setting up node-semver (7.3.5+~7.3.8-1) ...\n",
            "Setting up node-fs-write-stream-atomic (1.0.10-5) ...\n",
            "Setting up node-builtins (4.0.0-1) ...\n",
            "Setting up node-colors (1.4.0-3) ...\n",
            "Setting up node-log-driver (1.2.7+git+20180219+bba1761737-7) ...\n",
            "Setting up node-ssri (8.0.1-2) ...\n",
            "Setting up node-object-assign (4.1.1-6) ...\n",
            "Setting up node-end-of-stream (1.4.4+~1.4.1-1) ...\n",
            "Setting up node-pump (3.0.0-5) ...\n",
            "Setting up node-psl (1.8.0+ds-6) ...\n",
            "Setting up node-stack-utils (2.0.5+~2.0.1-1) ...\n",
            "Setting up node-json-buffer (3.0.1-1) ...\n",
            "Setting up node-console-control-strings (1.1.0-2) ...\n",
            "Setting up node-debug (4.3.2+~cs4.1.7-1) ...\n",
            "Setting up node-events (3.3.0+~3.0.0-2) ...\n",
            "Setting up node-agent-base (6.0.2+~cs5.4.2-1) ...\n",
            "Setting up node-validate-npm-package-name (3.0.0-4) ...\n",
            "Setting up node-wcwidth.js (1.0.2-1) ...\n",
            "Setting up node-cssstyle (2.3.0-2) ...\n",
            "Setting up node-spdx-correct (3.1.1-2) ...\n",
            "Setting up node-glob (7.2.1+~cs7.6.15-1) ...\n",
            "Setting up node-get-stream (6.0.1-1) ...\n",
            "Setting up node-got (11.8.3+~cs58.7.37-1) ...\n",
            "Setting up node-typedarray-to-buffer (4.0.0-2) ...\n",
            "Setting up node-tap-parser (7.0.0+ds1-6) ...\n",
            "Setting up node-minipass (3.1.6+~cs8.7.18-1) ...\n",
            "Setting up node-tough-cookie (4.0.0-2) ...\n",
            "Setting up node-npm-package-arg (8.1.5-1) ...\n",
            "Setting up node-https-proxy-agent (5.0.0+~cs8.0.0-3) ...\n",
            "Setting up node-rimraf (3.0.2-1) ...\n",
            "Setting up node-string-width (4.2.3+~cs13.2.3-1) ...\n",
            "Setting up node-validate-npm-package-license (3.0.4-2) ...\n",
            "Setting up node-write-file-atomic (3.0.3+~3.0.2-1) ...\n",
            "Setting up node-columnify (1.5.4+~1.5.1-1) ...\n",
            "Setting up node-copy-concurrently (1.0.5-8) ...\n",
            "Setting up node-move-concurrently (1.0.1-4) ...\n",
            "Setting up node-tap-mocha-reporter (3.0.7+ds-2) ...\n",
            "Setting up node-normalize-package-data (3.0.3+~2.4.1-1) ...\n",
            "Setting up node-ws (8.5.0+~cs13.3.3-2) ...\n",
            "Setting up node-cli-table (0.3.11+~cs0.13.3-1) ...\n",
            "Setting up node-jsdom (19.0.0+~cs90.11.27-1) ...\n",
            "Setting up node-tar (6.1.11+ds1+~cs6.0.6-1) ...\n",
            "Setting up node-wide-align (1.1.3-4) ...\n",
            "Setting up node-tap (12.0.1+ds-4) ...\n",
            "Setting up node-cacache (15.0.5+~cs13.9.21-3) ...\n",
            "Setting up node-read-package-json (4.1.1-1) ...\n",
            "Setting up node-fetch (2.6.7+~2.5.12-1) ...\n",
            "Setting up node-gauge (4.0.2-1) ...\n",
            "Setting up node-npmlog (6.0.1+~4.1.4-1) ...\n",
            "Setting up node-coveralls (3.1.1-1) ...\n",
            "Setting up node-gyp (8.4.1-1) ...\n",
            "Setting up npm (8.5.1~ds-1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new directory for your project\n",
        "!mkdir myproject\n",
        "%cd myproject\n",
        "\n",
        "# Initialize npm and install the package\n",
        "!npm init -y\n",
        "!npm install persian-swear-words\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_L1gt9544hH",
        "outputId": "19198627-1aa8-470d-b0fd-afc14aa1c1af"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/myproject/myproject/myproject/myproject/myproject\n",
            "Wrote to /content/myproject/myproject/myproject/myproject/myproject/package.json:\n",
            "\n",
            "{\n",
            "  \"name\": \"myproject\",\n",
            "  \"version\": \"1.0.0\",\n",
            "  \"description\": \"\",\n",
            "  \"main\": \"index.js\",\n",
            "  \"scripts\": {\n",
            "    \"test\": \"echo \\\"Error: no test specified\\\" && exit 1\"\n",
            "  },\n",
            "  \"keywords\": [],\n",
            "  \"author\": \"\",\n",
            "  \"license\": \"ISC\"\n",
            "}\n",
            "\n",
            "\n",
            "\u001b[K\u001b[?25h\n",
            "added 1 package, and audited 2 packages in 1s\n",
            "\n",
            "found \u001b[32m\u001b[1m0\u001b[22m\u001b[39m vulnerabilities\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from string import punctuation\n",
        "\n",
        "\n",
        "class PersianSwear:\n",
        "    def __init__(self):\n",
        "        with open(\"/content/myproject/myproject/myproject/myproject/myproject/node_modules/persian-swear-words/data.json\") as file:\n",
        "            self.data = json.load(file)\n",
        "        self.swear_words = set(self.data[\"word\"])\n",
        "\n",
        "    def ignoreSY(self, text):\n",
        "        translator = str.maketrans(\"\", \"\", punctuation)\n",
        "        return text.translate(translator)\n",
        "\n",
        "    def filter_words(self, text, symbol=\"*\", ignoreOT=False):\n",
        "        if not self.swear_words:\n",
        "            return text\n",
        "\n",
        "        words = text.split()\n",
        "        filtered_words = []\n",
        "        for word in words:\n",
        "            if word in self.swear_words or (\n",
        "                ignoreOT and self.ignoreSY(word) in self.swear_words\n",
        "            ):\n",
        "                filtered_words.append(symbol)\n",
        "            else:\n",
        "                filtered_words.append(word)\n",
        "\n",
        "        return \" \".join(filtered_words)\n",
        "\n",
        "    def is_empty(self):\n",
        "        return not self.swear_words\n",
        "\n",
        "    def add_word(self, word):\n",
        "        self.swear_words.add(word)\n",
        "        self.data[\"word\"].append(word)\n",
        "\n",
        "    def remove_word(self, word):\n",
        "        if word in self.swear_words:\n",
        "            self.swear_words.remove(word)\n",
        "        if word in self.data[\"word\"]:\n",
        "            self.data[\"word\"].remove(word)\n",
        "\n",
        "    def is_bad(self, text, ignoreOT=False):\n",
        "        if ignoreOT:\n",
        "            text = self.ignoreSY(text)\n",
        "        text = text.replace(\"\\u200c\", \"\")\n",
        "        return text in self.swear_words\n",
        "\n",
        "    def has_swear(self, text, ignoreOT=False):\n",
        "        if ignoreOT:\n",
        "            text = self.ignoreSY(text)\n",
        "        text = text.replace(\"\\u200c\", \"\")\n",
        "        if not self.swear_words:\n",
        "            return False\n",
        "\n",
        "        words = text.split()\n",
        "        return any(word in self.swear_words for word in words)\n",
        "\n",
        "    def tostring(self):\n",
        "        return \" - \".join(self.swear_words)"
      ],
      "metadata": {
        "id": "wBan1uaR5IC6"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "persianswear = PersianSwear()\n",
        "\n",
        "print(persianswear.is_bad('خر',ignoreOT=False )) # True\n",
        "\n",
        "print(persianswear.is_bad('امروز',ignoreOT=False )) # False\n",
        "\n",
        "print(persianswear.is_bad('چرت و پرت',ignoreOT=False )) # False\n",
        "\n",
        "persianswear.add_word('چرت و پرت')\n",
        "print(persianswear.is_bad('چرت و پرت' , ignoreOT=False )) # True\n",
        "\n",
        "print(persianswear.has_swear('تو دوست من هستی' , ignoreOT=False )) # False\n",
        "\n",
        "print(persianswear.has_swear('تو هیز هستی' , ignoreOT=False )) # True\n",
        "\n",
        "print(persianswear.filter_words('تو دوست من هستی' , ignoreOT=False )) # تو دوست من هستی\n",
        "\n",
        "print(persianswear.filter_words('تو هیز هستی' , ignoreOT=False )) # تو * هستی\n",
        "\n",
        "print(persianswear.filter_words('تو هیز هستی', '&' , ignoreOT=False )) # تو & هستی\n",
        "\n",
        "\n",
        "print(persianswear.is_bad('خ.ر' , ignoreOT=True )) # True\n",
        "\n",
        "print(persianswear.is_bad( 'ام.روز' , ignoreOT=True )) # False\n",
        "\n",
        "print(persianswear.has_swear('تو دو.ست من هستی' , ignoreOT=True )) # False\n",
        "\n",
        "print(persianswear.has_swear('تو اسک.ل هستی' , ignoreOT=True )) # True\n",
        "\n",
        "print(persianswear.filter_words('تو دو.ست من هستی',ignoreOT=True )) # تو دو.ست من هستی\n",
        "\n",
        "print(persianswear.filter_words('تو هی.ز هستی',ignoreOT=True )) # تو * هستی\n",
        "\n",
        "print(persianswear.filter_words('تو هی.ز هس.تی' , ignoreOT=True )) # تو * هس.تی\n",
        "\n",
        "print(persianswear.tostring()) # show all swear words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZcykA8z6btS",
        "outputId": "1555eca2-bfcf-4615-de79-6b20eea7ecf1"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "False\n",
            "False\n",
            "True\n",
            "False\n",
            "True\n",
            "تو دوست من هستی\n",
            "تو * هستی\n",
            "تو & هستی\n",
            "True\n",
            "False\n",
            "False\n",
            "True\n",
            "تو دو.ست من هستی\n",
            "تو * هستی\n",
            "تو * هس.تی\n",
            "حروم‌لقمه - دکل - زن جنده - پشم کون - کونی - لاشی - کوس خور - بی عفت - سگ صفت - اوسکل - ترک - سولاخ مادر - کیرر - کوص - دوست دختر - داف - پدر صلواتی - گوسفند - دودول طلا - عن دونی - زارت - خایه مال - بخورش - نعشه - عمه ننه - بچه کونی - مادرکونی - دهن سرویس - غرمساق - گاو - کس لیس - کون ده - ننه مرده - لاس - لخت - کوس - زنیکه - خار سولاخی - مرتیکه - پدر سوخته - بپرسرش - سگ پدر - زنازاده - بکیرم - کونشو - بی شرف - کسکش - کص - بدطینت - الاغ - بکارت - کوث لیس - زن قوه - کس خل - مادر فاکر - شهوتی - کصکش - دخترجنده - شغال - گوزو - بکن بکن - صیغه ای - بی غیرت - بیابخورش - مشروب - بدبخت - مغز پریودی - شق کردن - مادرسگ - اسب - دلقک - سلیطه - کس کش - ابله - بچه کیونی - احمق - بپرروش - کله کاندومی - رشتی - بی پدرو مادر - لاکونی - زنشو - فیلم سوپر - فرو کن - زرنزن - دهن گاییده - مادر جنده - جنسی - اوسگل - چاقال - عرب - کص لیس - خز - حشر - دخترقرتی - کردنی - آبم اومد - خبیث - بکنش - کوس خل - کس - کون - کرم - کیونی - شاش - پلشت - فاحشه خانم - زنتو - پدرسگ - کس کردن - لامصب - خپل - ساک بزن - بی خایه - خارکسده - پاچه‌خوار - خارکونی - سادیسمی - بی فانوس - اوصکل - توله سگ - سیکتیر - بکن - دوجنسه - عمتو - سوراخ کون - جفنگ - گایدن - کصکلک بازی - ممه - جکس - قرمدنگ - چسو - مادرجنده - چاغال - مردیکه - زنا - غرمصاق - بی پدر - عوضی - بیشعور - ناکس - کونی مقام - فاحشه - دهنتو گاییدم - ساک - ولدزنا - حشری - کیرمکیدن - مادرقهوه - بکنمت - سرخور - خایه خور - کیروکس - ماچ - گوه - خارکسّه - کسخل - سسکی - پستون - کسکیر - کون گنده - جوون - کیر خر - ملنگ - چوسو - کیرناز - گاوی - انگل - چرب کنش - جنده - سکسی - سکسیم - اسکل - زاخار - کیری - آب کیر - جنده پولی - مرض داری - سکسی باش - چس - قرتی - حیوانی - دهنتوببند - کصپدر - اسبی - هرزه - خر - کث - پورن - ریدن - خارکیونی - جاکش - شاش خالی - ریدی - گاییدن - کس لیسیدن - سولاخ - میخوریش - کثافت - بی عرضه - چرت و پرت - ریدم - ظنا - کیردراز - دوست پسر - سگی - دول ننه - انی - ماچ کردنی - گهی - کصخل - هیز - شاش بند - چس خوری - دیوث - لاشخور - قس - پسون - سکسیی - بی مصرف - خواهرجنده - کیر - شنگول - خنگ - کس ننت - فارس - بی آبرو - خارتو - کله کیری - خری - کوص لیس - خفه شو - بی شعور - سکس - خارکس ده - کونده - سکس چت - خرفت - بمال - بیناموس - لر - شومبول - کسپولی - آلت تناسلی - ننه هزار کیر - کس و کیر - گوش دراز - جنده خانه - زالو - کونن - خفه - آشغال - پپه - هزار پدر - گنده گوز - گایدی - کث لیس - اوصگل - عرق خور - پرده زن - لجن - گه - ان - مالوندن - عن - به تخم اقام - خایه - کس خیس - گاگول - سگ تو روحت - کس دادن - ساکونی - گوز - الاق - ممه خور - لز - لاش گوشت - ساکر - اوبی - دله - نرکده - خفه خون - قرمساق - کسشعر - بو زنا - دیوس خان - کوس لیس - گشاد - حرومی - ارگاسم - چس خور - کس خور - کیردوس - باسن - قرمصاق - دیوس - اوب - حشری شدن - کردن - سرکیر - گی مادر - کلفت - گردن دراز - دیوص - اسگل - مفت‌خور - آلت - کصپولی - خانم جنده - کیرم دهنت - جلق زدن - درازگوش - پستان - حرومزاده - پریود - دول - بکن توش - لختی - پشمام - مرضداری - داف ناز - پدر سگ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import re\n",
        "from string import punctuation\n",
        "\n",
        "class PersianSwear:\n",
        "    def __init__(self, swear_words_file='data.json'):\n",
        "        with open(swear_words_file, 'r', encoding='utf-8') as file:\n",
        "            self.data = json.load(file)\n",
        "        self.swear_words = set(self.data[\"word\"])\n",
        "\n",
        "    def ignoreSY(self, text):\n",
        "        translator = str.maketrans(\"\", \"\", punctuation)\n",
        "        return text.translate(translator)\n",
        "\n",
        "    def filter_words(self, text, symbol=\"*\", ignoreOT=False):\n",
        "        if not self.swear_words:\n",
        "            return text\n",
        "\n",
        "        words = text.split()\n",
        "        filtered_words = []\n",
        "        for word in words:\n",
        "            if word in self.swear_words or (\n",
        "                ignoreOT and self.ignoreSY(word) in self.swear_words\n",
        "            ):\n",
        "                filtered_words.append(symbol)\n",
        "            else:\n",
        "                filtered_words.append(word)\n",
        "\n",
        "        return \" \".join(filtered_words)\n",
        "\n",
        "    def is_empty(self):\n",
        "        return not self.swear_words\n",
        "\n",
        "    def add_word(self, word):\n",
        "        self.swear_words.add(word)\n",
        "        self.data[\"word\"].append(word)\n",
        "\n",
        "    def remove_word(self, word):\n",
        "        if word in self.swear_words:\n",
        "            self.swear_words.remove(word)\n",
        "        if word in self.data[\"word\"]:\n",
        "            self.data[\"word\"].remove(word)\n",
        "\n",
        "    def is_bad(self, text, ignoreOT=False):\n",
        "        if ignoreOT:\n",
        "            text = self.ignoreSY(text)\n",
        "        text = text.replace(\"\\u200c\", \"\")\n",
        "        return text in self.swear_words\n",
        "\n",
        "    def has_swear(self, text, ignoreOT=False):\n",
        "        if ignoreOT:\n",
        "            text = self.ignoreSY(text)\n",
        "        text = text.replace(\"\\u200c\", \"\")\n",
        "        if not self.swear_words:\n",
        "            return False\n",
        "\n",
        "        words = text.split()\n",
        "        return any(word in self.swear_words for word in words)\n",
        "\n",
        "    def tostring(self):\n",
        "        return \" - \".join(self.swear_words)\n",
        "\n",
        "# Initialize the PersianSwear instance\n",
        "persianswear = PersianSwear('/content/myproject/myproject/node_modules/persian-swear-words/data.json')\n",
        "\n",
        "# Load the CSV file into a DataFrame\n",
        "df = pd.read_csv('/content/tweets_replies.csv')\n",
        "\n",
        "# Check each tweet and its replies\n",
        "for index, row in df.iterrows():\n",
        "    tweet_id = row['Tweet ID']\n",
        "    tweet_text = row['Tweet Text']\n",
        "    reply_text = row['Replies']\n",
        "\n",
        "    # Check appropriateness\n",
        "    tweet_appropriate = not persianswear.has_swear(tweet_text)\n",
        "    reply_appropriate = not persianswear.has_swear(reply_text) if isinstance(reply_text, str) else True\n",
        "\n",
        "    # Print the results\n",
        "    print(f\"Tweet ID: {tweet_id}\")\n",
        "    print(f\"Tweet Text: {tweet_text}\")\n",
        "    print(f\"Tweet Appropriate: {'Yes' if tweet_appropriate else 'No'}\")\n",
        "\n",
        "    if isinstance(reply_text, str):\n",
        "        print(f\"Reply: {reply_text}\")\n",
        "        print(f\"Reply Appropriate: {'Yes' if reply_appropriate else 'No'}\")\n",
        "\n",
        "    print('-' * 40)  # Separator between entries\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjV1L-VLMXbZ",
        "outputId": "e8c48b53-38ff-4254-cde2-a8b5bebc62cc"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tweet ID: 1852625293518709216\n",
            "Tweet Text: @Napoleon_1995 ذهنم یکم درگیر شد👀\n",
            "Tweet Appropriate: Yes\n",
            "----------------------------------------\n",
            "Tweet ID: 1852615723488534819\n",
            "Tweet Text: @f_ysf11 (((((:\n",
            "Tweet Appropriate: Yes\n",
            "----------------------------------------\n",
            "Tweet ID: 1852614200746447189\n",
            "Tweet Text: @f_ysf11 بابا داره میگه چشماش قشنگن چه ربطیییی داره  الان  مثلا لانارودز چون پورن استاره باید بگیم زشته؟\n",
            "Tweet Appropriate: No\n",
            "----------------------------------------\n",
            "Tweet ID: 1852609968232386919\n",
            "Tweet Text: @HosseinamirA https://t.co/qiKF4jFVeg\n",
            "Tweet Appropriate: Yes\n",
            "----------------------------------------\n",
            "Tweet ID: 1852599909884580211\n",
            "Tweet Text: @Alibrr22 (((((((((=\n",
            "Tweet Appropriate: Yes\n",
            "----------------------------------------\n",
            "Tweet ID: 1852598372726620434\n",
            "Tweet Text: @CallClytie ملت عجیبن واقعا\n",
            "Tweet Appropriate: Yes\n",
            "----------------------------------------\n",
            "Tweet ID: 1852590777332867267\n",
            "Tweet Text: @ibe9901inahk https://t.co/WzS7pGcZSt\n",
            "Tweet Appropriate: Yes\n",
            "----------------------------------------\n",
            "Tweet ID: 1852590673783882008\n",
            "Tweet Text: @rad6602 اونقد گوه بود که پاک کردم\n",
            "Tweet Appropriate: No\n",
            "----------------------------------------\n",
            "Tweet ID: 1852461785972097198\n",
            "Tweet Text: @vaNajnde ((((((:\n",
            "Tweet Appropriate: Yes\n",
            "----------------------------------------\n",
            "Tweet ID: 1852459825441181947\n",
            "Tweet Text: رستتون کنیم؟شمارو خدا رست کرده بابا\n",
            "Tweet Appropriate: Yes\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KdctuLOdU-rO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "# Twitter API credentials\n",
        "\n",
        "\n",
        "consumer_key = 'blbcoMIZ5uCxAVSPzhyPb6zZy'\n",
        "consumer_secret = 'gmBI5znemhDOAGC24tMSMd2PzZJmaJrYfOg27zGYnyajUvB2qH'\n",
        "bearer_token = 'AAAAAAAAAAAAAAAAAAAAAHnzwgEAAAAAh%2FPgFJjdh7WmiEnzBCEGbu4F1Vg%3Di7Vd8mNuLIY7NFAI5UlExwJk9YSMS0pRv74h64zCHwfS7Jv56A'\n",
        "access_token = '1852584711966605312-zgsUN8CZXw7OKE1lFgMa27W7lJuh4e'\n",
        "access_token_secret = 'Fvqyz7BDeqVDIhdsb3POsEb637XJz0WaaqXgKna1KxKuX'\n",
        "\n",
        "# Set up headers for the request\n",
        "headers = {\n",
        "    \"Authorization\": f\"Bearer {bearer_token}\"\n",
        "}\n",
        "\n",
        "# Step 1: Fetch tweets using the user ID\n",
        "user_id = \"551857757\"  # Replace with the specific user ID\n",
        "\n",
        "tweets_url = f\"https://api.twitter.com/2/users/{user_id}/tweets\"\n",
        "\n",
        "tweets_response = requests.get(tweets_url, headers=headers)\n",
        "\n",
        "# Prepare a list to hold tweet and reply data\n",
        "data = []\n",
        "\n",
        "if tweets_response.status_code == 200:\n",
        "    tweets = tweets_response.json()\n",
        "    for tweet in tweets.get('data', []):\n",
        "        tweet_text = tweet['text']\n",
        "        tweet_id = tweet['id']\n",
        "        print(f\"Tweet: {tweet_text} (ID: {tweet_id})\")\n",
        "\n",
        "        # Step 2: Fetch replies to the specific tweet\n",
        "        replies_url = f\"https://api.twitter.com/2/tweets/{tweet_id}/replies\"\n",
        "        replies_response = requests.get(replies_url, headers=headers)\n",
        "\n",
        "        if replies_response.status_code == 200:\n",
        "            replies = replies_response.json()\n",
        "            replies_texts = [reply['text'] for reply in replies.get('data', [])]\n",
        "            replies_text = \"; \".join(replies_texts)  # Join replies into a single string\n",
        "            print(\"Replies:\", replies_text)\n",
        "        else:\n",
        "            print(f\"Error fetching replies: {replies_response.status_code} - {replies_response.text}\")\n",
        "            replies_text = \"Error fetching replies\"\n",
        "\n",
        "        # Add tweet and replies to the data list\n",
        "        data.append({\n",
        "            'Tweet ID': tweet_id,\n",
        "            'Tweet Text': tweet_text,\n",
        "            'Replies': replies_text\n",
        "        })\n",
        "else:\n",
        "    print(f\"Error fetching tweets: {tweets_response.status_code} - {tweets_response.text}\")\n",
        "\n",
        "# Create a DataFrame from the data list\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "df.to_csv('tweets_replies.csv', index=False, encoding='utf-8-sig')\n",
        "print(\"Data saved to tweets_replies.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmTrahSF8w73",
        "outputId": "4c611ec0-8a7d-47eb-9797-e5b878c3b8f2"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error fetching tweets: 429 - {\"title\":\"Too Many Requests\",\"detail\":\"Too Many Requests\",\"type\":\"about:blank\",\"status\":429}\n",
            "Data saved to tweets_replies.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "\n",
        "# Function to create headers for the request\n",
        "def create_headers(bearer_token):\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {bearer_token}\",\n",
        "        \"User-Agent\": \"v2UserLookupPython\"\n",
        "    }\n",
        "    return headers\n",
        "\n",
        "# Step 1: Get the User ID\n",
        "def get_user_id(username):\n",
        "    user_url = f\"https://api.twitter.com/2/users/by/username/{username}\"\n",
        "    headers = create_headers(bearer_token)\n",
        "    response = requests.get(user_url, headers=headers)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        user_data = response.json()\n",
        "        return user_data['data']['id']\n",
        "    else:\n",
        "        print(f\"Error fetching user ID: {response.status_code} - {response.text}\")\n",
        "        return None\n",
        "\n",
        "# Step 2: Get the First Tweet\n",
        "def get_first_tweet(user_id):\n",
        "    tweet_url = f\"https://api.twitter.com/2/users/{user_id}/tweets?max_results=5&tweet.fields=id,text\"\n",
        "    headers = create_headers(bearer_token)\n",
        "    response = requests.get(tweet_url, headers=headers)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        tweets = response.json()\n",
        "        if tweets['data']:\n",
        "            # Return the first tweet\n",
        "            return tweets['data'][0]['id']\n",
        "    else:\n",
        "        print(f\"Error fetching tweets: {response.status_code} - {response.text}\")\n",
        "    return None\n",
        "\n",
        "# Step 3: Get Replies to the First Tweet\n",
        "def get_replies(tweet_id):\n",
        "    url = f\"https://api.twitter.com/2/tweets/search/recent?query=conversation_id:{tweet_id}&tweet.fields=author_id,text\"\n",
        "    headers = create_headers(bearer_token)\n",
        "    response = requests.get(url, headers=headers)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        replies = response.json()\n",
        "        for reply in replies.get('data', []):\n",
        "            print(f\"User ID: {reply['author_id']}, Comment: {reply['text']}\")\n",
        "    else:\n",
        "        print(f\"Error fetching replies: {response.status_code} - {response.text}\")\n",
        "\n",
        "# Main logic\n",
        "user_id = get_user_id(username)\n",
        "if user_id:\n",
        "    tweet_id = get_first_tweet(user_id)\n",
        "    if tweet_id:\n",
        "        get_replies(tweet_id)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBs7Y8sVUvME",
        "outputId": "3fcaa12b-b2d7-4bb8-d893-223b79356123"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error fetching user ID: 429 - {\"title\":\"Too Many Requests\",\"detail\":\"Too Many Requests\",\"type\":\"about:blank\",\"status\":429}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tweepy\n",
        "username = 'digiato'\n",
        "\n",
        "consumer_key = 'blbcoMIZ5uCxAVSPzhyPb6zZy'\n",
        "consumer_secret = 'gmBI5znemhDOAGC24tMSMd2PzZJmaJrYfOg27zGYnyajUvB2qH'\n",
        "bearer_token = 'AAAAAAAAAAAAAAAAAAAAAHnzwgEAAAAAh%2FPgFJjdh7WmiEnzBCEGbu4F1Vg%3Di7Vd8mNuLIY7NFAI5UlExwJk9YSMS0pRv74h64zCHwfS7Jv56A'\n",
        "access_token = '1852584711966605312-zgsUN8CZXw7OKE1lFgMa27W7lJuh4e'\n",
        "access_token_secret = 'Fvqyz7BDeqVDIhdsb3POsEb637XJz0WaaqXgKna1KxKuX'\n",
        "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "api = tweepy.API(auth)"
      ],
      "metadata": {
        "id": "F-4uch2VXsvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "\n",
        "# Function to create headers for the request\n",
        "def create_headers(bearer_token):\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {bearer_token}\",\n",
        "        \"User-Agent\": \"v2UserLookupPython\"\n",
        "    }\n",
        "    return headers\n",
        "\n",
        "# Step 1: Get the User ID\n",
        "def get_user_id(username):\n",
        "    user_url = f\"https://api.twitter.com/2/users/by/username/{username}\"\n",
        "    headers = create_headers(bearer_token)\n",
        "    response = requests.get(user_url, headers=headers)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        user_data = response.json()\n",
        "        return user_data['data']['id']\n",
        "    else:\n",
        "        print(f\"Error fetching user ID: {response.status_code} - {response.text}\")\n",
        "        return None\n",
        "\n",
        "# Step 2: Get the First Tweet\n",
        "def get_first_tweet(user_id):\n",
        "    tweet_url = f\"https://api.twitter.com/2/users/{user_id}/tweets?max_results=5&tweet.fields=id,text\"\n",
        "    headers = create_headers(bearer_token)\n",
        "    response = requests.get(tweet_url, headers=headers)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        tweets = response.json()\n",
        "        if tweets['data']:\n",
        "            # Return the first tweet\n",
        "            return tweets['data'][0]['id']\n",
        "    else:\n",
        "        print(f\"Error fetching tweets: {response.status_code} - {response.text}\")\n",
        "    return None\n",
        "\n",
        "# Step 3: Get Replies to the First Tweet\n",
        "def get_replies(tweet_id):\n",
        "    url = f\"https://api.twitter.com/2/tweets/search/recent?query=conversation_id:{tweet_id}&tweet.fields=author_id,text\"\n",
        "    headers = create_headers(bearer_token)\n",
        "    response = requests.get(url, headers=headers)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        replies = response.json()\n",
        "        for reply in replies.get('data', []):\n",
        "            print(f\"User ID: {reply['author_id']}, Comment: {reply['text']}\")\n",
        "    else:\n",
        "        print(f\"Error fetching replies: {response.status_code} - {response.text}\")\n",
        "\n",
        "# Main logic\n",
        "user_id = get_user_id(username)\n",
        "if user_id:\n",
        "    tweet_id = get_first_tweet(user_id)\n",
        "    if tweet_id:\n",
        "        get_replies(tweet_id)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYymAfqoYKXp",
        "outputId": "e3ecff37-b574-4c95-d957-c01c73002e0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error fetching replies: 503 - {\"title\":\"Service Unavailable\",\"detail\":\"Service Unavailable\",\"type\":\"about:blank\",\"status\":503}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "username = 'SasanFarsani'\n",
        "\n",
        "# Step 1: Get the user ID from the username\n",
        "user_url = f\"https://api.twitter.com/2/users/by/username/{username}\"\n",
        "\n",
        "headers = {\n",
        "    \"Authorization\": f\"Bearer {bearer_token}\",\n",
        "}\n",
        "\n",
        "response = requests.get(user_url, headers=headers)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    user_data = response.json()\n",
        "    user_id = user_data['data']['id']\n",
        "    print(f\"User ID for {username}: {user_id}\")\n",
        "else:\n",
        "    print(f\"Error: {response.status_code} - {response.text}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ia7PXnZSYhp-",
        "outputId": "947c13bf-a5d2-4d13-c890-ff6801b477a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User ID for SasanFarsani: 30012897\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Fetch tweets using the user ID\n",
        "tweets_url = f\"https://api.twitter.com/2/users/{user_id}/tweets\"\n",
        "\n",
        "tweets_response = requests.get(tweets_url, headers=headers)\n",
        "\n",
        "if tweets_response.status_code == 200:\n",
        "    tweets = tweets_response.json()\n",
        "    for tweet in tweets.get('data', []):\n",
        "        print(tweet['text'])\n",
        "else:\n",
        "    print(f\"Error: {tweets_response.status_code} - {tweets_response.text}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9I4rZbnYrFS",
        "outputId": "011f8243-0bfd-40bd-c882-d84de8fe69f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: 429 - {\"title\":\"Too Many Requests\",\"detail\":\"Too Many Requests\",\"type\":\"about:blank\",\"status\":429}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import tweepy\n",
        "\n",
        "user_id = 30012897\n",
        "\n",
        "\n",
        "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "api = tweepy.API(auth)\n",
        "# Function to create headers for the request\n",
        "def create_headers(bearer_token):\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {bearer_token}\",\n",
        "        \"User-Agent\": \"v2ReplyLookupPython\"\n",
        "    }\n",
        "    return headers\n",
        "\n",
        "# Step 1: Get the First Tweet\n",
        "def get_first_tweet(user_id):\n",
        "    tweet_url = f\"https://api.twitter.com/2/users/{user_id}/tweets?max_results=5&tweet.fields=id,text\"\n",
        "    headers = create_headers(bearer_token)\n",
        "    response = requests.get(tweet_url, headers=headers)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        tweets = response.json()\n",
        "        if tweets['data']:\n",
        "            # Return the first tweet\n",
        "            return tweets['data'][-1]['id']  # Get the oldest tweet\n",
        "    else:\n",
        "        print(f\"Error fetching tweets: {response.status_code} - {response.text}\")\n",
        "    return None\n",
        "\n",
        "# Step 2: Get Replies to the First Tweet\n",
        "def get_replies(tweet_id):\n",
        "    url = f\"https://api.twitter.com/2/tweets/search/recent?query=conversation_id:{tweet_id}&tweet.fields=author_id,text\"\n",
        "    headers = create_headers(bearer_token)\n",
        "    response = requests.get(url, headers=headers)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        replies = response.json()\n",
        "        for reply in replies.get('data', []):\n",
        "            print(f\"User ID: {reply['author_id']}, Comment: {reply['text']}\")\n",
        "    else:\n",
        "        print(f\"Error fetching replies: {response.status_code} - {response.text}\")\n",
        "\n",
        "# Main logic\n",
        "tweet_id = get_first_tweet(user_id)\n",
        "if tweet_id:\n",
        "    print(f\"Fetching replies to tweet ID: {tweet_id}\")\n",
        "    get_replies(tweet_id)\n",
        "else:\n",
        "    print(\"No tweets found for this user.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPTHmxySY6v4",
        "outputId": "686e5aba-44fb-41e9-b9d5-281d4aea6265"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error fetching tweets: 429 - {\"title\":\"Too Many Requests\",\"detail\":\"Too Many Requests\",\"type\":\"about:blank\",\"status\":429}\n",
            "No tweets found for this user.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rate_limit_status = api.rate_limit_status()\n",
        "print(rate_limit_status)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JeepygIpg_9h",
        "outputId": "0dbeac20-ae76-4208-d61e-debd575502b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'rate_limit_context': {'access_token': '1842502996724236288-OwCSdL7sW6689gry1hTVvZ3Hi1nfjl'}, 'resources': {'lists': {'/lists/list': {'limit': 15, 'remaining': 15, 'reset': 1730529050}, '/lists/:id/tweets&GET': {'limit': 900, 'remaining': 900, 'reset': 1730529050}, '/lists/:id/followers&GET': {'limit': 180, 'remaining': 180, 'reset': 1730529050}, '/lists/memberships': {'limit': 75, 'remaining': 75, 'reset': 1730529050}, '/lists/:id&DELETE': {'limit': 300, 'remaining': 300, 'reset': 1730529050}, '/lists/subscriptions': {'limit': 15, 'remaining': 15, 'reset': 1730529050}, '/lists/:id&GET': {'limit': 75, 'remaining': 75, 'reset': 1730529050}, '/lists/members': {'limit': 900, 'remaining': 900, 'reset': 1730529050}, '/lists/subscribers/show': {'limit': 15, 'remaining': 15, 'reset': 1730529050}, '/lists/:id&PUT': {'limit': 300, 'remaining': 300, 'reset': 1730529050}, '/lists/show': {'limit': 75, 'remaining': 75, 'reset': 1730529050}, '/lists/ownerships': {'limit': 15, 'remaining': 15, 'reset': 1730529050}, '/lists/:id/members/:user_id&DELETE': {'limit': 300, 'remaining': 300, 'reset': 1730529050}, '/lists/subscribers': {'limit': 180, 'remaining': 180, 'reset': 1730529050}, '/lists/:id/members&POST': {'limit': 300, 'remaining': 300, 'reset': 1730529050}, '/lists/:id/members&GET': {'limit': 900, 'remaining': 900, 'reset': 1730529050}, '/lists/members/show': {'limit': 15, 'remaining': 15, 'reset': 1730529050}, '/lists/statuses': {'limit': 900, 'remaining': 900, 'reset': 1730529050}}, 'application': {'/application/rate_limit_status': {'limit': 180, 'remaining': 180, 'reset': 1730529050}}, 'mutes': {'/mutes/users/list': {'limit': 15, 'remaining': 15, 'reset': 1730529050}, '/mutes/users/ids': {'limit': 15, 'remaining': 15, 'reset': 1730529050}}, 'verify': {'/verify/:version/badge-violation': {'limit': 15, 'remaining': 15, 'reset': 1730529050}, '/verify/:version/badge-violation/violations': {'limit': 15, 'remaining': 15, 'reset': 1730529050}, '/verify/:version/intake': {'limit': 15, 'remaining': 15, 'reset': 1730529050}, '/verify/:version/document-formats': {'limit': 15, 'remaining': 15, 'reset': 1730529050}, '/verify/:version/id-document&GET': {'limit': 1000, 'remaining': 1000, 'reset': 1730529050}, '/verify/:version/id-document&POST': {'limit': 15, 'remaining': 15, 'reset': 1730529050}, '/verify/:version/access': {'limit': 15, 'remaining': 15, 'reset': 1730529050}, '/verify/:version/account-eligibility': {'limit': 15, 'remaining': 15, 'reset': 1730529050}}, 'admin_users': {'/admin_users': {'limit': 2000, 'remaining': 2000, 'reset': 1730529050}}, 'live_video_stream': {'/live_video_stream/status/:id': {'limit': 1000, 'remaining': 1000, 'reset': 1730529050}}, 'friendships': {'/friendships/outgoing': {'limit': 15, 'remaining': 15, 'reset': 1730529050}, '/friendships/list': {'limit': 200, 'remaining': 200, 'reset': 1730529050}, '/friendships/no_retweets/ids': {'limit': 15, 'remaining': 15, 'reset': 1730529050}, '/friendships/lookup': {'limit': 15, 'remaining': 15, 'reset': 1730529050}, '/friendships/incoming': {'limit': 15, 'remaining': 15, 'reset': 1730529050}, '/friendships/show': {'limit': 180, 'remaining': 180, 'reset': 1730529050}}, 'guide': {'/guide': {'limit': 180, 'remaining': 180, 'reset': 1730529050}, '/guide/get_explore_locations': {'limit': 100, 'remaining': 100, 'reset': 1730529050}, '/guide/explore_locations_with_autocomplete': {'limit': 200, 'remaining': 200, 'reset': 1730529050}}, 'auth': {'/auth/csrf_token': {'limit': 15, 'remaining': 15, 'reset': 1730529050}}, 'compliance': {'/compliance/jobs&POST': {'limit': 150, 'remaining': 150, 'reset': 1730529050}, '/compliance/jobs&GET': {'limit': 150, 'remaining': 150, 'reset': 1730529050}, '/compliance/jobs/:job_id': {'limit': 150, 'remaining': 150, 'reset': 1730529050}}, 'paseto': {'/paseto/token': {'limit': 100, 'remaining': 100, 'reset': 1730529050}}, 'blocks': {'/blocks/list': {'limit': 15, 'remaining': 15, 'reset': 1730529050}, '/blocks/create&POST': {'limit': 200, 'remaining': 200, 'reset': 1730529050}, '/blocks/ids': {'limit': 15, 'remaining': 15, 'reset': 1730529050}}, 'geo': {'/geo/similar_places': {'limit': 15, 'remaining': 15, 'reset': 1730529050}, '/geo/place_page': {'limit': 75, 'remaining': 75, 'reset': 1730529050}, '/geo/id/:place_id': {'limit': 75, 'remaining': 75, 'reset': 1730529050}, '/geo/reverse_geocode': {'limit': 15, 'remaining': 15, 'reset': 1730529050}, '/geo/search': {'limit': 15, 'remaining': 15, 'reset': 1730529050}}, 'users': {'/users/': {'limit': 900, 'remaining': 900, 'reset': 1730529050}, '/users/:id/list_memberships&GET': {'limit': 75, 'remaining': 75, 'reset': 1730529050}, '/users/:id': {'limit': 900, 'remaining': 900, 'reset': 1730529050}, '/users/:id/muting&POST': {'limit': 50, 'remaining': 50, 'reset': 1730529050}, '/users/report_spam': {'limit': 15, 'remaining': 15, 'reset': 1730529050}, '/users/:id/pinned_lists/:list_id&DELETE': {'limit': 50, 'remaining': 50, 'reset': 1730529050}, '/users/:source_user_id/blocking/:target_user_id&DELETE': {'limit': 50, 'remaining': 50, 'reset': 1730529050}, '/users/contributors/pending': {'limit': 2000, 'remaining': 2000, 'reset': 1730529050}, '/users/show/:id': {'limit': 900, 'remaining': 900, 'reset': 1730529050}, '/users/:source_user_id/following&POST': {'limit': 50, 'remaining': 50, 'reset': 1730529050}, '/users/:id/tweets': {'limit': 900, 'remaining': 900, 'reset': 1730529050}, '/users/:id/retweets/:source_tweet_id&DELETE': {'limit': 50, 'remaining': 50, 'reset': 1730529050}, '/users/search': {'limit': 900, 'remaining': 900, 'reset': 1730529050}, '/users/:id/likes&POST': {'limit': 50, 'remaining': 50, 'reset': 1730529050}, '/users/suggestions/:slug': {'limit': 15, 'remaining': 15, 'reset': 1730529050}, '/users/contributees/pending': {'limit': 200, 'remaining': 200, 'reset': 1730529050}, '/users/:id/retweets&POST': {'limit': 50, 'remaining': 50, 'reset': 1730529050}, '/users/profile_banner': {'limit': 180, 'remaining': 180, 'reset': 1730529050}, '/users/by/username/:source_username/following/:target_user_name&DELETE': {'limit': 50, 'remaining': 50, 'reset': 1730529050}, '/users/by/username/:handle/tweets': {'limit': 900, 'remaining': 900, 'reset': 1730529050}, '/users/derived_info': {'limit': 15, 'remaining': 15, 'reset': 1730529050}, '/users/:id/blocking&POST': {'limit': 50, 'remaining': 50, 'reset': 1730529050}, '/users/by/username/:source_username/following&POST': {'limit': 50, 'remaining': 50, 'reset': 1730529050}, '/users/:id/followers': {'limit': 15, 'remaining': 15, 'reset': 1730529050}, '/users/suggestions/:slug/members': {'limit': 15, 'remaining': 15, 'reset': 1730529050}, '/users/:id/muting': {'limit': 15, 'remaining': 15, 'reset': 1730529050}, '/users/:id/pinned_lists&GET': {'limit': 15, 'remaining': 15, 'reset': 1730529050}, '/users/:id/mentions': {'limit': 180, 'remaining': 180, 'reset': 1730529050}, '/users/:id/following': {'limit': 15, 'remaining': 15, 'reset': 1730529050}, '/users/:id/pinned_lists&POST': {'limit': 50, 'remaining': 50, 'reset': 1730529050}, '/users/:source_user_id/following/:target_user_id&DELETE': {'limit': 50, 'remaining': 50, 'reset': 1730529050}, '/users/by/username/:username': {'limit': 900, 'remaining': 900, 'reset': 1730529050}, '/users/:id/owned_lists&GET': {'limit': 15, 'remaining': 15, 'reset': 1730529050}, '/users/:id/followed_lists&POST': {'limit': 50, 'remaining': 50, 'reset': 1730529050}, '/users/by/username/:username/followers': {'limit': 15, 'remaining': 15, 'reset': 1730529050}, '/users/lookup': {'limit': 900, 'remaining': 900, 'reset': 1730529050}, '/users/:id/followed_lists/:list_id&DELETE': {'limit': 50, 'remaining': 50, 'reset': 1730529050}, '/users/:id/blocking': {'limit': 15, 'remaining': 15, 'reset': 1730529050}, '/users/suggestions': {'limit': 15, 'remaining': 15, 'reset': 1730529050}, '/users/:id/likes/:tweet_id&DELETE': {'limit': 50, 'remaining': 50, 'reset': 1730529050}, '/users/by/username/:username/following': {'limit': 15, 'remaining': 15, 'reset': 1730529050}, '/users/by/username/:handle/mentions': {'limit': 180, 'remaining': 180, 'reset': 1730529050}, '/users/by': {'limit': 900, 'remaining': 900, 'reset': 1730529050}, '/users/:source_user_id/muting/:target_user_id&DELETE': {'limit': 50, 'remaining': 50, 'reset': 1730529050}, '/users/:id/followed_lists&GET': {'limit': 15, 'remaining': 15, 'reset': 1730529050}, '/users/:id/liked_tweets': {'limit': 75, 'remaining': 75, 'reset': 1730529050}}, 'teams': {'/teams/authorize': {'limit': 15, 'remaining': 15, 'reset': 1730529050}}, 'followers': {'/followers/ids': {'limit': 15, 'remaining': 15, 'reset': 1730529050}, '/followers/list': {'limit': 15, 'remaining': 15, 'reset': 1730529050}}, 'collections': {'/collections/list': {'limit': 1000, 'remaining': 1000, 'reset': 1730529050}, '/collections/entries': {'limit': 1000, 'remaining': 1000, 'reset': 1730529050}, '/collections/show': {'limit': 1000, 'remaining': 1000, 'reset': 1730529050}}, 'permissions': {'/permissions/user_permissions/admin_email_verification': {'limit': 3, 'remaining': 3, 'reset': 1730529050}, '/permissions/user_permissions': {'limit': 3, 'remaining': 3, 'reset': 1730529050}}, 'tweets&POST': {'/tweets&POST': {'limit': 200, 'remaining': 200, 'reset': 1730529050}}, 'statuses': {'/statuses/retweeters/ids': {'limit': 75, 'remaining': 75, 'reset': 1730529050}, '/statuses/retweets_of_me': {'limit': 75, 'remaining': 75, 'reset': 1730529050}, '/statuses/home_timeline': {'limit': 15, 'remaining': 15, 'reset': 1730529050}, '/statuses/show/:id': {'limit': 900, 'remaining': 900, 'reset': 1730529050}, '/statuses/user_timeline': {'limit': 900, 'remaining': 900, 'reset': 1730529050}, '/statuses/friends': {'limit': 15, 'remaining': 15, 'reset': 1730529050}, '/statuses/retweets/:id': {'limit': 75, 'remaining': 75, 'reset': 1730529050}, '/statuses/mentions_timeline': {'limit': 75, 'remaining': 75, 'reset': 1730529050}, '/statuses/oembed': {'limit': 180, 'remaining': 180, 'reset': 1730529050}, '/statuses/lookup': {'limit': 900, 'remaining': 900, 'reset': 1730529050}}, 'custom_profiles': {'/custom_profiles/list': {'limit': 180, 'remaining': 180, 'reset': 1730529050}, '/custom_profiles/show': {'limit': 180, 'remaining': 180, 'reset': 1730529050}}, 'webhooks': {'/webhooks/subscriptions/direct_messages': {'limit': 15, 'remaining': 15, 'reset': 1730529050}, '/webhooks': {'limit': 15, 'remaining': 15, 'reset': 1730529050}}, 'contacts': {'/contacts/uploaded_by': {'limit': 300, 'remaining': 300, 'reset': 1730529050}, '/contacts/users': {'limit': 300, 'remaining': 300, 'reset': 1730529050}, '/contacts/addressbook': {'limit': 300, 'remaining': 300, 'reset': 1730529050}, '/contacts/users_and_uploaded_by': {'limit': 300, 'remaining': 300, 'reset': 1730529050}, '/contacts/delete/status': {'limit': 300, 'remaining': 300, 'reset': 1730529050}}, 'labs': {'/labs/2/platform_manipulation/reports': {'limit': 5, 'remaining': 5, 'reset': 1730529050}, '/labs/:version/tweets/:id/hidden&PUT': {'limit': 10, 'remaining': 10, 'reset': 1730529050}, '/labs/:version/tweets/stream/filter/': {'limit': 50, 'remaining': 50, 'reset': 1730529050}, '/labs/:version/users/:id/tweets': {'limit': 225, 'remaining': 225, 'reset': 1730529050}, '/labs/2/reports': {'limit': 5, 'remaining': 5, 'reset': 1730529050}, '/labs/:version/tweets/stream/filter/rules&POST': {'limit': 450, 'remaining': 450, 'reset': 1730529050}, '/labs/:version/tweets/stream/sample': {'limit': 50, 'remaining': 50, 'reset': 1730529050}, '/labs/:version/users/by/username/:handle/tweets': {'limit': 225, 'remaining': 225, 'reset': 1730529050}, '/labs/:version/tweets/metrics/private': {'limit': 15, 'remaining': 15, 'reset': 1730529050}, '/labs/:version/tweets/stream/filter/rules/:instance_name': {'limit': 450, 'remaining': 450, 'reset': 1730529050}, '/labs/:version/tweets/*': {'limit': 900, 'remaining': 900, 'reset': 1730529050}, '/labs/:version/users/*': {'limit': 900, 'remaining': 900, 'reset': 1730529050}, '/labs/:version/tweets/stream/filter/:instance_name': {'limit': 50, 'remaining': 50, 'reset': 1730529050}, '/labs/:version/tweets/stream/filter/rules/': {'limit': 450, 'remaining': 450, 'reset': 1730529050}, '/labs/:version/tweets/stream/compliance': {'limit': 500, 'remaining': 500, 'reset': 1730529050}, '/labs/:version/tweets/search': {'limit': 225, 'remaining': 225, 'reset': 1730529050}}, 'i': {'/i/config': {'limit': 15, 'remaining': 15, 'reset': 1730529050}, '/i/tfb/v1/smb/web/:account_id/payment/save': {'limit': 15, 'remaining': 15, 'reset': 1730529050}}, 'tweet_prompts': {'/tweet_prompts/report_interaction': {'limit': 180, 'remaining': 180, 'reset': 1730529050}, '/tweet_prompts/show': {'limit': 180, 'remaining': 180, 'reset': 1730529050}}, 'moments': {'/moments/statuses/update': {'limit': 5, 'remaining': 5, 'reset': 1730529050}, '/moments/create': {'limit': 15, 'remaining': 15, 'reset': 1730529050}, '/moments/permissions': {'limit': 300, 'remaining': 300, 'reset': 1730529050}}, 'limiter_scalding_report_creation': {'/limiter_scalding_report_creation': {'limit': 4500, 'remaining': 4500, 'reset': 1730529050}}, 'fleets': {'/fleets/:version/mutes/create': {'limit': 100, 'remaining': 100, 'reset': 1730529050}, '/fleets/:version/viewers': {'limit': 100, 'remaining': 100, 'reset': 1730529050}, '/fleets/:version/delete': {'limit': 50, 'remaining': 50, 'reset': 1730529050}, '/fleets/:version/avatar_content': {'limit': 100, 'remaining': 100, 'reset': 1730529050}, '/fleets/:version/create': {'limit': 50, 'remaining': 50, 'reset': 1730529050}, '/fleets/:version/user_fleets': {'limit': 180, 'remaining': 180, 'reset': 1730529050}, '/fleets/:version/fleetline': {'limit': 100, 'remaining': 100, 'reset': 1730529050}, '/fleets/:version/track_events': {'limit': 100, 'remaining': 100, 'reset': 1730529050}, '/fleets/:version/update': {'limit': 50, 'remaining': 50, 'reset': 1730529050}, '/fleets/:version/fleet_threads': {'limit': 1000, 'remaining': 1000, 'reset': 1730529050}, '/fleets/:version/mutes/list': {'limit': 100, 'remaining': 100, 'reset': 1730529050}, '/fleets/:version/mutes/destroy': {'limit': 100, 'remaining': 100, 'reset': 1730529050}, '/fleets/:version/home_timeline': {'limit': 100, 'remaining': 100, 'reset': 1730529050}, '/fleets/:version/feedback/create': {'limit': 500, 'remaining': 500, 'reset': 1730529050}, '/fleets/:version/mark_read': {'limit': 1000, 'remaining': 1000, 'reset': 1730529050}}, 'help': {'/help/tos': {'limit': 15, 'remaining': 15, 'reset': 1730529050}, '/help/configuration': {'limit': 15, 'remaining': 15, 'reset': 1730529050}, '/help/settings': {'limit': 15, 'remaining': 15, 'reset': 1730529050}, '/help/privacy': {'limit': 15, 'remaining': 15, 'reset': 1730529050}, '/help/languages': {'limit': 15, 'remaining': 15, 'reset': 1730529050}}, 'feedback': {'/feedback/show/:id': {'limit': 180, 'remaining': 180, 'reset': 1730529050}, '/feedback/events': {'limit': 1000, 'remaining': 1000, 'reset': 1730529050}}, 'business_experience': {'/business_experience/dashboard_settings/destroy': {'limit': 450, 'remaining': 450, 'reset': 1730529050}, '/business_experience/dashboard_features': {'limit': 450, 'remaining': 450, 'reset': 1730529050}, '/business_experience/keywords': {'limit': 450, 'remaining': 450, 'reset': 1730529050}, '/business_experience/dashboard_settings/update': {'limit': 450, 'remaining': 450, 'reset': 1730529050}, '/business_experience/dashboard_settings/show': {'limit': 450, 'remaining': 450, 'reset': 1730529050}}, 'limiter': {'/limiter/ci_test/do/not/change&GET': {'limit': 4321, 'remaining': 4321, 'reset': 1730529050}}, 'graphql&POST': {'/graphql&POST': {'limit': 15, 'remaining': 15, 'reset': 1730529050}}, 'friends': {'/friends/following/ids': {'limit': 15, 'remaining': 15, 'reset': 1730529050}, '/friends/following/list': {'limit': 15, 'remaining': 15, 'reset': 1730529050}, '/friends/list': {'limit': 15, 'remaining': 15, 'reset': 1730529050}, '/friends/ids': {'limit': 15, 'remaining': 15, 'reset': 1730529050}}, 'sandbox': {'/sandbox/account_activity/webhooks/:id/subscriptions': {'limit': 500, 'remaining': 500, 'reset': 1730529050}}, 'drafts': {'/drafts/statuses/update': {'limit': 450, 'remaining': 450, 'reset': 1730529050}, '/drafts/statuses/destroy': {'limit': 450, 'remaining': 450, 'reset': 1730529050}, '/drafts/statuses/ids': {'limit': 450, 'remaining': 450, 'reset': 1730529050}, '/drafts/statuses/list': {'limit': 450, 'remaining': 450, 'reset': 1730529050}, '/drafts/statuses/show': {'limit': 450, 'remaining': 450, 'reset': 1730529050}, '/drafts/statuses/create': {'limit': 450, 'remaining': 450, 'reset': 1730529050}}, 'direct_messages': {'/direct_messages/sent': {'limit': 300, 'remaining': 300, 'reset': 1730529050}, '/direct_messages/broadcasts/list': {'limit': 60, 'remaining': 60, 'reset': 1730529050}, '/direct_messages/subscribers/lists/members/show': {'limit': 1000, 'remaining': 1000, 'reset': 1730529050}, '/direct_messages/mark_read': {'limit': 1000, 'remaining': 1000, 'reset': 1730529050}, '/direct_messages/subscribers/ids': {'limit': 180, 'remaining': 180, 'reset': 1730529050}, '/direct_messages/sent_and_received': {'limit': 300, 'remaining': 300, 'reset': 1730529050}, '/direct_messages/broadcasts/statuses/list': {'limit': 60, 'remaining': 60, 'reset': 1730529050}, '/direct_messages': {'limit': 300, 'remaining': 300, 'reset': 1730529050}, '/direct_messages/subscribers/lists/members/ids': {'limit': 180, 'remaining': 180, 'reset': 1730529050}, '/direct_messages/subscribers/show': {'limit': 180, 'remaining': 180, 'reset': 1730529050}, '/direct_messages/broadcasts/show': {'limit': 60, 'remaining': 60, 'reset': 1730529050}, '/direct_messages/broadcasts/statuses/show': {'limit': 60, 'remaining': 60, 'reset': 1730529050}, '/direct_messages/subscribers/lists/list': {'limit': 180, 'remaining': 180, 'reset': 1730529050}, '/direct_messages/show': {'limit': 300, 'remaining': 300, 'reset': 1730529050}, '/direct_messages/events/list': {'limit': 15, 'remaining': 15, 'reset': 1730529050}, '/direct_messages/subscribers/lists/show': {'limit': 180, 'remaining': 180, 'reset': 1730529050}, '/direct_messages/events/show': {'limit': 15, 'remaining': 15, 'reset': 1730529050}}, 'media': {'/media/upload': {'limit': 500, 'remaining': 500, 'reset': 1730529050}}, 'traffic': {'/traffic/map': {'limit': 15, 'remaining': 15, 'reset': 1730529050}}, 'strato': {'/strato/column/None/:id/cms/*': {'limit': 150, 'remaining': 150, 'reset': 1730529050}}, 'account_activity': {'/account_activity/all/webhooks': {'limit': 15, 'remaining': 15, 'reset': 1730529050}, '/account_activity/all/:instance_name/subscriptions': {'limit': 500, 'remaining': 500, 'reset': 1730529050}, '/account_activity/direct_messages/webhooks': {'limit': 15, 'remaining': 15, 'reset': 1730529050}, '/account_activity/webhooks/:id/subscriptions/direct_messages/list': {'limit': 15, 'remaining': 15, 'reset': 1730529050}, '/account_activity/webhooks/:id/subscriptions/all': {'limit': 500, 'remaining': 500, 'reset': 1730529050}, '/account_activity/direct_messages/:instance_name/webhooks': {'limit': 15, 'remaining': 15, 'reset': 1730529050}, '/account_activity/webhooks/:id/subscriptions/all/list': {'limit': 15, 'remaining': 15, 'reset': 1730529050}, '/account_activity/webhooks/:id/subscriptions/direct_messages': {'limit': 500, 'remaining': 500, 'reset': 1730529050}, '/account_activity/webhooks': {'limit': 15, 'remaining': 15, 'reset': 1730529050}, '/account_activity/direct_messages/:instance_name/subscriptions': {'limit': 15, 'remaining': 15, 'reset': 1730529050}, '/account_activity/webhooks/:id/subscriptions': {'limit': 500, 'remaining': 500, 'reset': 1730529050}, '/account_activity/all/:instance_name/webhooks': {'limit': 15, 'remaining': 15, 'reset': 1730529050}}, 'account': {'/account/login_verification_enrollment': {'limit': 15, 'remaining': 15, 'reset': 1730529050}, '/account/update_profile': {'limit': 15, 'remaining': 15, 'reset': 1730529050}, '/account/authenticate_web_view': {'limit': 50, 'remaining': 50, 'reset': 1730529050}, '/account/verify_credentials': {'limit': 75, 'remaining': 75, 'reset': 1730529050}, '/account/settings': {'limit': 15, 'remaining': 15, 'reset': 1730529050}, '/account/personalization/p13n_preferences': {'limit': 900, 'remaining': 900, 'reset': 1730529050}, '/account/change_password': {'limit': 15, 'remaining': 15, 'reset': 1730529050}}, 'safety': {'/safety/detection_feedback': {'limit': 450000, 'remaining': 450000, 'reset': 1730529050}}, 'favorites': {'/favorites/list': {'limit': 75, 'remaining': 75, 'reset': 1730529050}}, 'lists&POST': {'/lists&POST': {'limit': 300, 'remaining': 300, 'reset': 1730529050}}, 'device': {'/device/token': {'limit': 15, 'remaining': 15, 'reset': 1730529050}}, 'tweets': {'/tweets/search/all': {'limit': 900, 'remaining': 900, 'reset': 1730529050}, '/tweets/search/stream/rules': {'limit': 450, 'remaining': 450, 'reset': 1730529050}, '/tweets/search/recent': {'limit': 180, 'remaining': 180, 'reset': 1730529050}, '/tweets/sample/stream': {'limit': 50, 'remaining': 50, 'reset': 1730529050}, '/tweets/:id&DELETE': {'limit': 50, 'remaining': 50, 'reset': 1730529050}, '/tweets/': {'limit': 900, 'remaining': 900, 'reset': 1730529050}, '/tweets/counts/all': {'limit': 900, 'remaining': 900, 'reset': 1730529050}, '/tweets/search/stream': {'limit': 50, 'remaining': 50, 'reset': 1730529050}, '/tweets/search/:product/:label': {'limit': 1800, 'remaining': 1800, 'reset': 1730529050}, '/tweets/search/stream/rules/validation&POST': {'limit': 450, 'remaining': 450, 'reset': 1730529050}, '/tweets/search/:product/:instance/counts': {'limit': 900, 'remaining': 900, 'reset': 1730529050}, '/tweets/:id/retweeted_by': {'limit': 75, 'remaining': 75, 'reset': 1730529050}, '/tweets/:tweet_id/liking_users': {'limit': 75, 'remaining': 75, 'reset': 1730529050}, '/tweets/:id': {'limit': 900, 'remaining': 900, 'reset': 1730529050}, '/tweets/search/stream/rules&DELETE': {'limit': 450, 'remaining': 450, 'reset': 1730529050}, '/tweets/counts/recent': {'limit': 900, 'remaining': 900, 'reset': 1730529050}, '/tweets/search/stream/rules&POST': {'limit': 450, 'remaining': 450, 'reset': 1730529050}, '/tweets/:id/hidden&PUT': {'limit': 50, 'remaining': 50, 'reset': 1730529050}}, 'saved_searches': {'/saved_searches/destroy/:id': {'limit': 15, 'remaining': 15, 'reset': 1730529050}, '/saved_searches/show/:id': {'limit': 15, 'remaining': 15, 'reset': 1730529050}, '/saved_searches/list': {'limit': 15, 'remaining': 15, 'reset': 1730529050}}, 'oauth': {'/oauth/revoke': {'limit': 15, 'remaining': 15, 'reset': 1730529050}, '/oauth/invalidate_token': {'limit': 450, 'remaining': 450, 'reset': 1730529050}, '/oauth/revoke_html': {'limit': 15, 'remaining': 15, 'reset': 1730529050}}, 'search': {'/search/tweets': {'limit': 180, 'remaining': 180, 'reset': 1730529050}}, 'trends': {'/trends/closest': {'limit': 75, 'remaining': 75, 'reset': 1730529050}, '/trends/available': {'limit': 75, 'remaining': 75, 'reset': 1730529050}, '/trends/place': {'limit': 75, 'remaining': 75, 'reset': 1730529050}}, 'live_pipeline': {'/live_pipeline/events': {'limit': 180, 'remaining': 180, 'reset': 1730529050}}, 'graphql': {'/graphql': {'limit': 15, 'remaining': 15, 'reset': 1730529050}}}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install webdriver-manager\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2N8ofcxaKye",
        "outputId": "e1091030-799b-4cfa-ffa8-b4171b588ae5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting webdriver-manager\n",
            "  Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from webdriver-manager) (2.32.3)\n",
            "Collecting python-dotenv (from webdriver-manager)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from webdriver-manager) (24.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->webdriver-manager) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->webdriver-manager) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->webdriver-manager) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->webdriver-manager) (2024.8.30)\n",
            "Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl (27 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv, webdriver-manager\n",
            "Successfully installed python-dotenv-1.0.1 webdriver-manager-4.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "\n",
        "# Specify the path to the Chrome binary\n",
        "chrome_options = Options()\n",
        "chrome_options.binary_location = 'C:\\Program Files\\Google\\Chrome\\Application'  # Update this path\n",
        "\n",
        "# Set up the driver\n",
        "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n"
      ],
      "metadata": {
        "id": "3rAhf52ga1h9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "import time\n",
        "\n",
        "# Set up the driver (Chrome in this case)\n",
        "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
        "\n",
        "try:\n",
        "    # Open Twitter and search for the hashtag\n",
        "    hashtag = \"دلار\"\n",
        "    search_url = f\"https://twitter.com/search?q=%23{hashtag}&src=typed_query\"\n",
        "    driver.get(search_url)\n",
        "    time.sleep(5)  # Allow time for the page to load\n",
        "\n",
        "    # Get the first tweet on the page\n",
        "    tweet = driver.find_element(By.XPATH, \"//article[@role='article']\")\n",
        "    tweet.click()\n",
        "    time.sleep(5)  # Allow time for the tweet to load\n",
        "\n",
        "    # Scroll to load comments (may need to adjust scrolls based on the number of comments)\n",
        "    for _ in range(5):\n",
        "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "        time.sleep(2)  # Wait a bit for comments to load\n",
        "\n",
        "    # Retrieve all comments under the tweet\n",
        "    comments = driver.find_elements(By.XPATH, \"//div[@data-testid='reply']\")\n",
        "    comment_texts = [comment.text for comment in comments]\n",
        "\n",
        "    # Print each comment\n",
        "    for i, comment in enumerate(comment_texts, start=1):\n",
        "        print(f\"Comment {i}: {comment}\\n\")\n",
        "\n",
        "finally:\n",
        "    driver.quit()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        },
        "id": "OZcXTbBtaN1j",
        "outputId": "7f40cb26-7afb-44be-dc44-725ffbd66870"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "WebDriverException",
          "evalue": "Message: unknown error: cannot find Chrome binary\nStacktrace:\n#0 0x5abb136954e3 <unknown>\n#1 0x5abb133c4c76 <unknown>\n#2 0x5abb133eb757 <unknown>\n#3 0x5abb133ea029 <unknown>\n#4 0x5abb13428ccc <unknown>\n#5 0x5abb1342847f <unknown>\n#6 0x5abb1341fde3 <unknown>\n#7 0x5abb133f52dd <unknown>\n#8 0x5abb133f634e <unknown>\n#9 0x5abb136553e4 <unknown>\n#10 0x5abb136593d7 <unknown>\n#11 0x5abb13663b20 <unknown>\n#12 0x5abb1365a023 <unknown>\n#13 0x5abb136281aa <unknown>\n#14 0x5abb1367e6b8 <unknown>\n#15 0x5abb1367e847 <unknown>\n#16 0x5abb1368e243 <unknown>\n#17 0x7a723bb33ac3 <unknown>\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-bca36bd2b3e0>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Set up the driver (Chrome in this case)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdriver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mChrome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mservice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mService\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mChromeDriverManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/selenium/webdriver/chrome/webdriver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, options, service, keep_alive)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptions\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moptions\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m     46\u001b[0m             \u001b[0mbrowser_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDesiredCapabilities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCHROME\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"browserName\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mvendor_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"goog\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/selenium/webdriver/chromium/webdriver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, browser_name, vendor_prefix, options, service, keep_alive)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexecutor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, command_executor, keep_alive, file_detector, options, locator_converter, web_element_cls, client_config)\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_authenticator_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_client\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcapabilities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_websocket_connection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mstart_session\u001b[0;34m(self, capabilities)\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0mcaps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_create_caps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcapabilities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNEW_SESSION\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sessionId\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"capabilities\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m             \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unwrap_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/selenium/webdriver/remote/errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    227\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"alert\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mWebDriverException\u001b[0m: Message: unknown error: cannot find Chrome binary\nStacktrace:\n#0 0x5abb136954e3 <unknown>\n#1 0x5abb133c4c76 <unknown>\n#2 0x5abb133eb757 <unknown>\n#3 0x5abb133ea029 <unknown>\n#4 0x5abb13428ccc <unknown>\n#5 0x5abb1342847f <unknown>\n#6 0x5abb1341fde3 <unknown>\n#7 0x5abb133f52dd <unknown>\n#8 0x5abb133f634e <unknown>\n#9 0x5abb136553e4 <unknown>\n#10 0x5abb136593d7 <unknown>\n#11 0x5abb13663b20 <unknown>\n#12 0x5abb1365a023 <unknown>\n#13 0x5abb136281aa <unknown>\n#14 0x5abb1367e6b8 <unknown>\n#15 0x5abb1367e847 <unknown>\n#16 0x5abb1368e243 <unknown>\n#17 0x7a723bb33ac3 <unknown>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install twikit pandas\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tArUdUytdw4_",
        "outputId": "e9410341-9de8-4a8d-d335-3a0c4721287f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting twikit\n",
            "  Downloading twikit-2.1.3-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: httpx[socks] in /usr/local/lib/python3.10/dist-packages (from twikit) (0.27.2)\n",
            "Collecting filetype (from twikit)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from twikit) (4.12.3)\n",
            "Collecting pyotp (from twikit)\n",
            "  Downloading pyotp-2.9.0-py3-none-any.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from twikit) (5.3.0)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->twikit) (2.6)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx[socks]->twikit) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx[socks]->twikit) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx[socks]->twikit) (1.0.6)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx[socks]->twikit) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx[socks]->twikit) (1.3.1)\n",
            "Collecting socksio==1.* (from httpx[socks]->twikit)\n",
            "  Downloading socksio-1.0.0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx[socks]->twikit) (0.14.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx[socks]->twikit) (1.2.2)\n",
            "Downloading twikit-2.1.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.7/71.7 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading socksio-1.0.0-py3-none-any.whl (12 kB)\n",
            "Downloading pyotp-2.9.0-py3-none-any.whl (13 kB)\n",
            "Installing collected packages: filetype, socksio, pyotp, twikit\n",
            "Successfully installed filetype-1.2.0 pyotp-2.9.0 socksio-1.0.0 twikit-2.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from twikit import Client\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "async def main():\n",
        "    client = Client('en-US')\n",
        "\n",
        "    ## You can comment this `login`` part out after the first time you run the script (and you have the `cookies.json`` file)\n",
        "    await client.login(\n",
        "        auth_info_1='Annk159305',\n",
        "        password='894Sa866',\n",
        "    )\n",
        "\n",
        "    await client.save_cookies('cookies.json')\n",
        "    await client.load_cookies(path='cookies.json')\n",
        "\n",
        "    user = await client.get_user_by_screen_name('digiato')\n",
        "    tweets = await user.get_tweets('Tweets', count=5)\n",
        "\n",
        "    tweets_to_store = []\n",
        "\n",
        "    for tweet in tweets:\n",
        "        tweets_to_store.append({\n",
        "            'created_at': tweet.created_at,\n",
        "            'favorite_count': tweet.favorite_count,\n",
        "            'full_text': tweet.full_text,\n",
        "        })\n",
        "\n",
        "    # We can make the data into a pandas dataframe and store it as a CSV file\n",
        "    df = pd.DataFrame(tweets_to_store)\n",
        "    df.to_csv('tweets.csv', index=False)\n",
        "\n",
        "    # Pandas also allows us to sort or filter the data\n",
        "    print(df.sort_values(by='favorite_count', ascending=False))\n",
        "\n",
        "    # We can also print the data as a JSON object\n",
        "    print(json.dumps(tweets_to_store, indent=4))\n",
        "\n",
        "# Directly await the main function in Jupyter\n",
        "await main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "8cHc79OsdXKx",
        "outputId": "e23bdf61-07e6-49d5-ae8f-cf29472b28bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "BadRequest",
          "evalue": "status: 400, message: \"{\"errors\":[{\"code\":366,\"message\":\"Required input 'LoginAcid' not provided.\"}]}\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBadRequest\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-9c151c1f0a44>\u001b[0m in \u001b[0;36m<cell line: 40>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# Directly await the main function in Jupyter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0;32mawait\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-42-9c151c1f0a44>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m## You can comment this `login`` part out after the first time you run the script (and you have the `cookies.json`` file)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     await client.login(\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mauth_info_1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Annk159305'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'894Sa866'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/twikit/client/client.py\u001b[0m in \u001b[0;36mlogin\u001b[0;34m(self, auth_info_1, auth_info_2, password, totp_secret)\u001b[0m\n\u001b[1;32m    398\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTwitterException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'subtasks'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cta'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'secondary_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m         await flow.execute_task({\n\u001b[0m\u001b[1;32m    401\u001b[0m             \u001b[0;34m'subtask_id'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'AccountDuplicationCheck'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             'check_logged_in_account': {\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/twikit/utils.py\u001b[0m in \u001b[0;36mexecute_task\u001b[0;34m(self, *subtask_inputs, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mexecute_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0msubtask_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         response, _ = await self._client.v11.onboarding_task(\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mguest_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubtask_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/twikit/client/v11.py\u001b[0m in \u001b[0;36monboarding_task\u001b[0;34m(self, guest_token, token, subtask_inputs, data, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'X-Twitter-Auth-Type'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         return await self.base.post(\n\u001b[0m\u001b[1;32m     86\u001b[0m             \u001b[0mEndpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mONBOARDING_TASK\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/twikit/client/client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, url, **kwargs)\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mResponse\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;34m':meta private:'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'POST'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_remove_duplicate_ct0_cookie\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/twikit/client/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, auto_unlock, raise_exception, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'status: {status_code}, message: \"{response.text}\"'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus_code\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mBadRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mstatus_code\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m401\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mUnauthorized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBadRequest\u001b[0m: status: 400, message: \"{\"errors\":[{\"code\":366,\"message\":\"Required input 'LoginAcid' not provided.\"}]}\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import tweepy\n",
        "import time\n",
        "\n",
        "# Replace these with your actual Twitter API credentials\n",
        "consumer_key = \"YOUR_CONSUMER_KEY\"\n",
        "consumer_secret = \"YOUR_CONSUMER_SECRET\"\n",
        "access_token = \"YOUR_ACCESS_TOKEN\"\n",
        "access_token_secret = \"YOUR_ACCESS_TOKEN_SECRET\"\n",
        "bearer_token = \"YOUR_BEARER_TOKEN\"\n",
        "\n",
        "# Authenticate with the Twitter API\n",
        "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "api = tweepy.API(auth)\n",
        "\n",
        "# Function to create headers for the request\n",
        "def create_headers(bearer_token):\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {bearer_token}\",\n",
        "        \"User-Agent\": \"v2ReplyLookupPython\"\n",
        "    }\n",
        "    return headers\n",
        "\n",
        "# Function to handle rate limits and server unavailability with exponential backoff\n",
        "def make_request_with_retry(url, headers):\n",
        "    max_retries = 5\n",
        "    retry_count = 0\n",
        "    while retry_count < max_retries:\n",
        "        response = requests.get(url, headers=headers)\n",
        "        if response.status_code == 200:\n",
        "            return response.json()\n",
        "        elif response.status_code in [429, 503]:  # Handle both rate limit and service unavailable errors\n",
        "            retry_count += 1\n",
        "            wait_time = 2 ** retry_count  # Exponential backoff\n",
        "            print(f\"Server unavailable or rate limit hit. Retrying in {wait_time} seconds...\")\n",
        "            time.sleep(wait_time)\n",
        "        else:\n",
        "            print(f\"Error: {response.status_code} - {response.text}\")\n",
        "            break\n",
        "    return None\n",
        "\n",
        "# Step 1: Get the First Tweet\n",
        "def get_first_tweet(user_id):\n",
        "    tweet_url = f\"https://api.twitter.com/2/users/{user_id}/tweets?max_results=5&tweet.fields=id,text\"\n",
        "    headers = create_headers(bearer_token)\n",
        "    tweets = make_request_with_retry(tweet_url, headers)\n",
        "\n",
        "    if tweets and tweets.get('data'):\n",
        "        # Return the first tweet (oldest in this case)\n",
        "        return tweets['data'][-1]['id']\n",
        "    print(\"No tweets found for this user.\")\n",
        "    return None\n",
        "\n",
        "# Step 2: Get Replies to the First Tweet\n",
        "def get_replies(tweet_id):\n",
        "    url = f\"https://api.twitter.com/2/tweets/search/recent?query=conversation_id:{tweet_id}&tweet.fields=author_id,text\"\n",
        "    headers = create_headers(bearer_token)\n",
        "    replies = make_request_with_retry(url, headers)\n",
        "\n",
        "    if replies and replies.get('data'):\n",
        "        for reply in replies['data']:\n",
        "            print(f\"User ID: {reply['author_id']}, Comment: {reply['text']}\")\n",
        "    else:\n",
        "        print(\"No replies found or an error occurred.\")\n",
        "\n",
        "# Main logic\n",
        "user_id = 30012897  # Replace with the user ID you want to query\n",
        "tweet_id = get_first_tweet(user_id)\n",
        "if tweet_id:\n",
        "    print(f\"Fetching replies to tweet ID: {tweet_id}\")\n",
        "    get_replies(tweet_id)\n",
        "else:\n",
        "    print(\"No tweets found for this user.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpjrFON8hZDy",
        "outputId": "e1f2e6ce-0270-471c-d68b-6ac35b17beb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: 401 - {\n",
            "  \"title\": \"Unauthorized\",\n",
            "  \"type\": \"about:blank\",\n",
            "  \"status\": 401,\n",
            "  \"detail\": \"Unauthorized\"\n",
            "}\n",
            "No tweets found for this user.\n",
            "No tweets found for this user.\n"
          ]
        }
      ]
    }
  ]
}